% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.3 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global/global}
    \entry{abakumov_pyguitarpro_2014}{online}{}{}
      \name{author}{1}{}{%
        {{hash=5684edfca0da48de7097c6c5f8a40be4}{%
           family={Abakumov},
           familyi={A\bibinitperiod},
           given={Sviatoslav},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{5684edfca0da48de7097c6c5f8a40be4}
      \strng{fullhash}{5684edfca0da48de7097c6c5f8a40be4}
      \strng{fullhashraw}{5684edfca0da48de7097c6c5f8a40be4}
      \strng{bibnamehash}{5684edfca0da48de7097c6c5f8a40be4}
      \strng{authorbibnamehash}{5684edfca0da48de7097c6c5f8a40be4}
      \strng{authornamehash}{5684edfca0da48de7097c6c5f8a40be4}
      \strng{authorfullhash}{5684edfca0da48de7097c6c5f8a40be4}
      \strng{authorfullhashraw}{5684edfca0da48de7097c6c5f8a40be4}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{PyGuitarPro} — {PyGuitarPro} 0.9.3 documentation}
      \field{year}{2014}
      \field{dateera}{ce}
      \verb{file}
      \verb PyGuitarPro — PyGuitarPro 0.9.3 documentation:C\:\\Users\\oanou\\Zotero\\storage\\G6Z7J5TF\\stable.html:text/html
      \endverb
    \endentry
    \entry{agarwal_structure-informed_2024}{inproceedings}{}{}
      \name{author}{3}{}{%
        {{hash=8beae8a1b061b334b96cde68f968a111}{%
           family={Agarwal},
           familyi={A\bibinitperiod},
           given={Manvi},
           giveni={M\bibinitperiod}}}%
        {{hash=03478ba871580b32ae5fd2efb39834c6}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Changhong},
           giveni={C\bibinitperiod}}}%
        {{hash=aec7d43f7c5ea1426c242ee4c14428fd}{%
           family={Richard},
           familyi={R\bibinitperiod},
           given={Gaël},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{1a763db84a268c0c684fc76f5ea9278b}
      \strng{fullhash}{1a763db84a268c0c684fc76f5ea9278b}
      \strng{fullhashraw}{1a763db84a268c0c684fc76f5ea9278b}
      \strng{bibnamehash}{1a763db84a268c0c684fc76f5ea9278b}
      \strng{authorbibnamehash}{1a763db84a268c0c684fc76f5ea9278b}
      \strng{authornamehash}{1a763db84a268c0c684fc76f5ea9278b}
      \strng{authorfullhash}{1a763db84a268c0c684fc76f5ea9278b}
      \strng{authorfullhashraw}{1a763db84a268c0c684fc76f5ea9278b}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Music generated by deep learning methods often suffers from a lack of coherence and long-term organization. Yet, multi-scale hierarchical structure is a distinctive feature of music signals. To leverage this information, we propose a structure-informed positional encoding framework for music generation with Transformers. We design three variants in terms of absolute, relative and non-stationary positional information. We comprehensively test them on two symbolic music generation tasks: next-timestep prediction and accompaniment generation. As a comparison, we choose multiple baselines from the literature and demonstrate the merits of our methods using several musically-motivated evaluation metrics. In particular, our methods improve the melodic and structural consistency of the generated pieces.}
      \field{eventtitle}{{IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{title}{Structure-informed Positional Encoding for Music Generation}
      \field{year}{2024}
      \field{dateera}{ce}
      \verb{file}
      \verb Full Text PDF:C\:\\Users\\oanou\\Zotero\\storage\\8RHZJ7ET\\Agarwal et al. - 2024 - Structure-informed Positional Encoding for Music Generation.pdf:application/pdf
      \endverb
    \endentry
    \entry{bacot_tablature_2025}{unpublished}{}{}
      \name{author}{3}{}{%
        {{hash=ba95b2016803444a955389769db3227e}{%
           family={Bacot},
           familyi={B\bibinitperiod},
           given={Baptiste},
           giveni={B\bibinitperiod}}}%
        {{hash=e686bdd8fdd2a400c824e6aa9dd01ffd}{%
           family={Bigo},
           familyi={B\bibinitperiod},
           given={Louis},
           giveni={L\bibinitperiod}}}%
        {{hash=3fdacc578798399e8cab0dd6dfdcfccd}{%
           family={Navarret},
           familyi={N\bibinitperiod},
           given={Benoît},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{d04725a75e07cbdcf662b9ae39987d84}
      \strng{fullhash}{d04725a75e07cbdcf662b9ae39987d84}
      \strng{fullhashraw}{d04725a75e07cbdcf662b9ae39987d84}
      \strng{bibnamehash}{d04725a75e07cbdcf662b9ae39987d84}
      \strng{authorbibnamehash}{d04725a75e07cbdcf662b9ae39987d84}
      \strng{authornamehash}{d04725a75e07cbdcf662b9ae39987d84}
      \strng{authorfullhash}{d04725a75e07cbdcf662b9ae39987d84}
      \strng{authorfullhashraw}{d04725a75e07cbdcf662b9ae39987d84}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Tablature software and popular music composition: a user study and perspectives on creative algorithmic tools}
      \field{year}{2025}
      \field{dateera}{ce}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\4DYNZDRQ\\Bacot et al. - Tablature software and popular music composition a user study and perspectives on creative algorit.pdf:application/pdf
      \endverb
    \endentry
    \entry{cournut_encodages_2020}{inproceedings}{}{}
      \name{author}{4}{}{%
        {{hash=cd9d78ef1e376597538e28076434c388}{%
           family={Cournut},
           familyi={C\bibinitperiod},
           given={Jules},
           giveni={J\bibinitperiod}}}%
        {{hash=e686bdd8fdd2a400c824e6aa9dd01ffd}{%
           family={Bigo},
           familyi={B\bibinitperiod},
           given={Louis},
           giveni={L\bibinitperiod}}}%
        {{hash=15c1382498ea9d34a03b78c94ec4b7d1}{%
           family={Giraud},
           familyi={G\bibinitperiod},
           given={Mathieu},
           giveni={M\bibinitperiod}}}%
        {{hash=0e114fcb893c9e96e896bc25a778900a}{%
           family={Martin},
           familyi={M\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{f21f5cddc537e5eb08e0d36e25518fa1}
      \strng{fullhash}{bdf6fe6a0d7df2e3b367b967afa075fb}
      \strng{fullhashraw}{bdf6fe6a0d7df2e3b367b967afa075fb}
      \strng{bibnamehash}{f21f5cddc537e5eb08e0d36e25518fa1}
      \strng{authorbibnamehash}{f21f5cddc537e5eb08e0d36e25518fa1}
      \strng{authornamehash}{f21f5cddc537e5eb08e0d36e25518fa1}
      \strng{authorfullhash}{bdf6fe6a0d7df2e3b367b967afa075fb}
      \strng{authorfullhashraw}{bdf6fe6a0d7df2e3b367b967afa075fb}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Journées d'Informatique Musicale ({JIM} 2020)}
      \field{title}{Encodages de tablatures pour l'analyse de musique pour guitare}
      \field{year}{2020}
      \field{dateera}{ce}
      \verb{file}
      \verb HAL PDF Full Text:C\:\\Users\\oanou\\Zotero\\storage\\845FRSUL\\Cournut et al. - 2020 - Encodages de tablatures pour l'analyse de musique pour guitare.pdf:application/pdf
      \endverb
    \endentry
    \entry{dai_transformer-xl_2019}{inproceedings}{}{}
      \name{author}{6}{}{%
        {{hash=74ae4c193de464cda59c8066619514fd}{%
           family={Dai},
           familyi={D\bibinitperiod},
           given={Zihang},
           giveni={Z\bibinitperiod}}}%
        {{hash=6b1fa069ba3a41402c63a24209e47289}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Zhilin},
           giveni={Z\bibinitperiod}}}%
        {{hash=be6dc43fe1771d8870237ce7a47c6f7f}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Yiming},
           giveni={Y\bibinitperiod}}}%
        {{hash=4e523aba9ce388c6b542f2f6e52293c2}{%
           family={Carbonell},
           familyi={C\bibinitperiod},
           given={Jaime},
           giveni={J\bibinitperiod}}}%
        {{hash=841a83a4bb5e622d6e1bde4818879016}{%
           family={Le},
           familyi={L\bibinitperiod},
           given={Quoc},
           giveni={Q\bibinitperiod}}}%
        {{hash=bd2be300d445e9f6db7808f9533e66cb}{%
           family={Salakhutdinov},
           familyi={S\bibinitperiod},
           given={Ruslan},
           giveni={R\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=088f1cd997c8227387a06e1cb2dc1538}{%
           family={Korhonen},
           familyi={K\bibinitperiod},
           given={Anna},
           giveni={A\bibinitperiod}}}%
        {{hash=852889328d57da2df5bccea3165205d0}{%
           family={Traum},
           familyi={T\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=98a908240c23e42cd08857cd67e53cff}{%
           family={Màrquez},
           familyi={M\bibinitperiod},
           given={Lluís},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Association for Computational Linguistics}%
      }
      \strng{namehash}{64f332e195de5d241c9866cc6621f71f}
      \strng{fullhash}{e28267dd567ba8c114b09efa1fe06f1e}
      \strng{fullhashraw}{e28267dd567ba8c114b09efa1fe06f1e}
      \strng{bibnamehash}{64f332e195de5d241c9866cc6621f71f}
      \strng{authorbibnamehash}{64f332e195de5d241c9866cc6621f71f}
      \strng{authornamehash}{64f332e195de5d241c9866cc6621f71f}
      \strng{authorfullhash}{e28267dd567ba8c114b09efa1fe06f1e}
      \strng{authorfullhashraw}{e28267dd567ba8c114b09efa1fe06f1e}
      \strng{editorbibnamehash}{5d0d019d65674f287aa73e6f7f5b6291}
      \strng{editornamehash}{5d0d019d65674f287aa73e6f7f5b6291}
      \strng{editorfullhash}{5d0d019d65674f287aa73e6f7f5b6291}
      \strng{editorfullhashraw}{5d0d019d65674f287aa73e6f7f5b6291}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-{XL} that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-{XL} learns dependency that is 80\% longer than {RNNs} and 450\% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on {WikiText}-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on {WikiText}-103, Transformer-{XL} manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and {PyTorch}.}
      \field{booktitle}{Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}
      \field{eventtitle}{{ACL} 2019}
      \field{title}{Transformer-{XL}: Attentive Language Models beyond a Fixed-Length Context}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{pages}{2978\bibrangedash 2988}
      \range{pages}{11}
      \verb{file}
      \verb Full Text PDF:C\:\\Users\\oanou\\Zotero\\storage\\BG9H8M2U\\Dai et al. - 2019 - Transformer-XL Attentive Language Models beyond a Fixed-Length Context.pdf:application/pdf
      \endverb
    \endentry
    \entry{graves_framewise_2005}{inproceedings}{}{}
      \name{author}{2}{}{%
        {{hash=e9bdfa299b60985e61d954d9c8981eaa}{%
           family={Graves},
           familyi={G\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod}}}%
        {{hash=07e9fb186fd9976e6be82e64365dc308}{%
           family={Schmidhuber},
           familyi={S\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{7e975189adf40e111a86121ecb34b06d}
      \strng{fullhash}{7e975189adf40e111a86121ecb34b06d}
      \strng{fullhashraw}{7e975189adf40e111a86121ecb34b06d}
      \strng{bibnamehash}{7e975189adf40e111a86121ecb34b06d}
      \strng{authorbibnamehash}{7e975189adf40e111a86121ecb34b06d}
      \strng{authornamehash}{7e975189adf40e111a86121ecb34b06d}
      \strng{authorfullhash}{7e975189adf40e111a86121ecb34b06d}
      \strng{authorfullhashraw}{7e975189adf40e111a86121ecb34b06d}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we apply bidirectional training to a Long Short Term Memory ({LSTM}) network for the ﬁrst time. We also present a modiﬁed, full gradient version of the {LSTM} learning algorithm. We discuss the signiﬁcance of framewise phoneme classiﬁcation to continuous speech recognition, and the validity of using bidirectional networks for online causal tasks. On the {TIMIT} speech database, we measure the framewise phoneme classiﬁcation scores of bidirectional and unidirectional variants of both {LSTM} and conventional Recurrent Neural Networks ({RNNs}). We ﬁnd that bidirectional {LSTM} outperforms both {RNNs} and unidirectional {LSTM}.}
      \field{booktitle}{Proceedings. 2005 {IEEE} International Joint Conference on Neural Networks, 2005.}
      \field{eventtitle}{International Joint Conference on Neural Networks 2005}
      \field{title}{Framewise phoneme classification with bidirectional {LSTM} networks}
      \field{volume}{4}
      \field{year}{2005}
      \field{dateera}{ce}
      \field{pages}{2047\bibrangedash 2052}
      \range{pages}{6}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\KU43FU95\\Graves et Schmidhuber - 2005 - Framewise phoneme classification with bidirectional LSTM networks.pdf:application/pdf
      \endverb
    \endentry
    \entry{green_how_2001}{book}{}{}
      \name{author}{1}{}{%
        {{hash=72cf86a36254c095943bc74b78409f9d}{%
           family={Green},
           familyi={G\bibinitperiod},
           given={Lucy},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{72cf86a36254c095943bc74b78409f9d}
      \strng{fullhash}{72cf86a36254c095943bc74b78409f9d}
      \strng{fullhashraw}{72cf86a36254c095943bc74b78409f9d}
      \strng{bibnamehash}{72cf86a36254c095943bc74b78409f9d}
      \strng{authorbibnamehash}{72cf86a36254c095943bc74b78409f9d}
      \strng{authornamehash}{72cf86a36254c095943bc74b78409f9d}
      \strng{authorfullhash}{72cf86a36254c095943bc74b78409f9d}
      \strng{authorfullhashraw}{72cf86a36254c095943bc74b78409f9d}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Popular musicians acquire some or all of their skills and knowledge informally, outside school or university, and with little help from trained instrumental teachers. How do they go about this process? Despite the fact that popular music has recently entered formal music education, we have as yet a limited understanding of the learning practices adopted by its musicians. Nor do we know why so many popular musicians in the past turned away from music education, or how young popular musicians toda}
      \field{title}{How Popular Musicians Learn: A Way Ahead for Music Education}
      \field{year}{2001}
      \field{dateera}{ce}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\Z4U9YB3F\\How Popular Musicians Learn A Way Ahead for Music Education.pdf:application/pdf
      \endverb
    \endentry
    \entry{hawthorne_enabling_2018}{inproceedings}{}{}
      \name{author}{9}{}{%
        {{hash=4102bf268c4922002c51584dbb63c959}{%
           family={Hawthorne},
           familyi={H\bibinitperiod},
           given={Curtis},
           giveni={C\bibinitperiod}}}%
        {{hash=bd9ccff49b29cb00d6855ab66232a1ab}{%
           family={Stasyuk},
           familyi={S\bibinitperiod},
           given={Andriy},
           giveni={A\bibinitperiod}}}%
        {{hash=243c03e5ae8031582d6af9fcbc70f629}{%
           family={Roberts},
           familyi={R\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod}}}%
        {{hash=0b461ec7764bb41a6287a8d0716006a0}{%
           family={Simon},
           familyi={S\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
        {{hash=9406d3118ff06a9e9b1fc218f4106061}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Cheng-Zhi\bibnamedelima Anna},
           giveni={C\bibinithyphendelim Z\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=a133b469b21b870786119a47b1b691eb}{%
           family={Dieleman},
           familyi={D\bibinitperiod},
           given={Sander},
           giveni={S\bibinitperiod}}}%
        {{hash=6aa92a937d4d30dd0b5ec0eecbad1bf1}{%
           family={Elsen},
           familyi={E\bibinitperiod},
           given={Erich},
           giveni={E\bibinitperiod}}}%
        {{hash=84488af703576ab131f87436b63aeef0}{%
           family={Engel},
           familyi={E\bibinitperiod},
           given={Jesse},
           giveni={J\bibinitperiod}}}%
        {{hash=b2c4631ad93e93115d9b3ceea6587550}{%
           family={Eck},
           familyi={E\bibinitperiod},
           given={Douglas},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{dc875fb44266eb3f98e6aa2c898eaf27}
      \strng{fullhash}{d7b3447bf817650a9fae3d8e5c821a04}
      \strng{fullhashraw}{d7b3447bf817650a9fae3d8e5c821a04}
      \strng{bibnamehash}{dc875fb44266eb3f98e6aa2c898eaf27}
      \strng{authorbibnamehash}{dc875fb44266eb3f98e6aa2c898eaf27}
      \strng{authornamehash}{dc875fb44266eb3f98e6aa2c898eaf27}
      \strng{authorfullhash}{d7b3447bf817650a9fae3d8e5c821a04}
      \strng{authorfullhashraw}{d7b3447bf817650a9fae3d8e5c821a04}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Generating musical audio directly with neural networks is notoriously difficult because it requires coherently modeling structure at many different timescales. Fortunately, most music is also highly structured and can be represented as discrete note events played on musical instruments. Herein, we show that by using notes as an intermediate representation, we can train a suite of models capable of transcribing, composing, and synthesizing audio waveforms with coherent musical structure on timescales spanning six orders of magnitude ({\textasciitilde}0.1 ms to {\textasciitilde}100 s), a process we call Wave2Midi2Wave. This large advance in the state of the art is enabled by our release of the new {MAESTRO} ({MIDI} and Audio Edited for Synchronous {TRacks} and Organization) dataset, composed of over 172 hours of virtuosic piano performances captured with fine alignment ({\textasciitilde}3 ms) between note labels and audio waveforms. The networks and the dataset together present a promising approach toward creating new expressive and interpretable neural models of music.}
      \field{eventtitle}{International Conference on Learning Representations}
      \field{title}{Enabling Factorized Piano Music Modeling and Generation with the {MAESTRO} Dataset}
      \field{year}{2018}
      \field{dateera}{ce}
      \verb{file}
      \verb Full Text PDF:C\:\\Users\\oanou\\Zotero\\storage\\3TVR5IC5\\Hawthorne et al. - 2018 - Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset.pdf:application/pdf
      \endverb
    \endentry
    \entry{hove_superior_2014}{article}{}{}
      \name{author}{4}{}{%
        {{hash=ecfbfe494f3f0cdfe664dfd362790772}{%
           family={Hove},
           familyi={H\bibinitperiod},
           given={Michael\bibnamedelima J.},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=851e7704e2296c8c3824396f3f6898cf}{%
           family={Marie},
           familyi={M\bibinitperiod},
           given={Céline},
           giveni={C\bibinitperiod}}}%
        {{hash=bca146383feba67171e6fd1128a06f1c}{%
           family={Bruce},
           familyi={B\bibinitperiod},
           given={Ian\bibnamedelima C.},
           giveni={I\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=6e69b432ce9180408a31a7679f62d147}{%
           family={Trainor},
           familyi={T\bibinitperiod},
           given={Laurel\bibnamedelima J.},
           giveni={L\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{269dc36c901db3e46208b5dd84458b8e}
      \strng{fullhash}{ea883c7107ce87729fe2da47ef86e560}
      \strng{fullhashraw}{ea883c7107ce87729fe2da47ef86e560}
      \strng{bibnamehash}{269dc36c901db3e46208b5dd84458b8e}
      \strng{authorbibnamehash}{269dc36c901db3e46208b5dd84458b8e}
      \strng{authornamehash}{269dc36c901db3e46208b5dd84458b8e}
      \strng{authorfullhash}{ea883c7107ce87729fe2da47ef86e560}
      \strng{authorfullhashraw}{ea883c7107ce87729fe2da47ef86e560}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The auditory environment typically contains several sound sources that overlap in time, and the auditory system parses the complex sound wave into streams or voices that represent the various sound sources. Music is also often polyphonic. Interestingly, the main melody (spectral/pitch information) is most often carried by the highest-pitched voice, and the rhythm (temporal foundation) is most often laid down by the lowest-pitched voice. Previous work using electroencephalography ({EEG}) demonstrated that the auditory cortex encodes pitch more robustly in the higher of two simultaneous tones or melodies, and modeling work indicated that this high-voice superiority for pitch originates in the sensory periphery. Here, we investigated the neural basis of carrying rhythmic timing information in lower-pitched voices. We presented simultaneous high-pitched and low-pitched tones in an isochronous stream and occasionally presented either the higher or the lower tone 50 ms earlier than expected, while leaving the other tone at the expected time. {EEG} recordings revealed that mismatch negativity responses were larger for timing deviants of the lower tones, indicating better timing encoding for lower-pitched compared with higher-pitch tones at the level of auditory cortex. A behavioral motor task revealed that tapping synchronization was more influenced by the lower-pitched stream. Results from a biologically plausible model of the auditory periphery suggest that nonlinear cochlear dynamics contribute to the observed effect. The low-voice superiority effect for encoding timing explains the widespread musical practice of carrying rhythm in bass-ranged instruments and complements previously established high-voice superiority effects for pitch and melody.}
      \field{journaltitle}{Proceedings of the National Academy of Sciences}
      \field{number}{28}
      \field{title}{Superior time perception for lower musical pitch explains why bass-ranged instruments lay down musical rhythms}
      \field{volume}{111}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{pages}{10383\bibrangedash 10388}
      \range{pages}{6}
      \verb{file}
      \verb Full Text PDF:C\:\\Users\\oanou\\Zotero\\storage\\C8LB4FST\\Hove et al. - 2014 - Superior time perception for lower musical pitch explains why bass-ranged instruments lay down music.pdf:application/pdf
      \endverb
    \endentry
    \entry{hsiao_compound_2021}{article}{}{}
      \name{author}{4}{}{%
        {{hash=f47bb192428e72b66eb056ce28de7dda}{%
           family={Hsiao},
           familyi={H\bibinitperiod},
           given={Wen-Yi},
           giveni={W\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=5ae179d9fb81470267f662a100c374a2}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Jen-Yu},
           giveni={J\bibinithyphendelim Y\bibinitperiod}}}%
        {{hash=3c74b5330607cde44cbcfaec7ad290c0}{%
           family={Yeh},
           familyi={Y\bibinitperiod},
           given={Yin-Cheng},
           giveni={Y\bibinithyphendelim C\bibinitperiod}}}%
        {{hash=dc4d44f6814797864181d8ee2756517f}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Yi-Hsuan},
           giveni={Y\bibinithyphendelim H\bibinitperiod}}}%
      }
      \strng{namehash}{ab7dc58b23ee37c4cdc4f1b7d8baf3c1}
      \strng{fullhash}{304272da05fb2486682b208b04e4043d}
      \strng{fullhashraw}{304272da05fb2486682b208b04e4043d}
      \strng{bibnamehash}{ab7dc58b23ee37c4cdc4f1b7d8baf3c1}
      \strng{authorbibnamehash}{ab7dc58b23ee37c4cdc4f1b7d8baf3c1}
      \strng{authornamehash}{ab7dc58b23ee37c4cdc4f1b7d8baf3c1}
      \strng{authorfullhash}{304272da05fb2486682b208b04e4043d}
      \strng{authorfullhashraw}{304272da05fb2486682b208b04e4043d}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{To apply neural sequence models such as the Transformers to music generation tasks, one has to represent a piece of music by a sequence of tokens drawn from a finite set of pre-defined vocabulary. Such a vocabulary usually involves tokens of various types. For example, to describe a musical note, one needs separate tokens to indicate the note’s pitch, duration, velocity (dynamics), and placement (onset time) along the time grid. While different types of tokens may possess different properties, existing models usually treat them equally, in the same way as modeling words in natural languages. In this paper, we present a conceptually different approach that explicitly takes into account the type of the tokens, such as note types and metric types. And, we propose a new Transformer decoder architecture that uses different feed-forward heads to model tokens of different types. With an expansion-compression trick, we convert a piece of music to a sequence of compound words by grouping neighboring tokens, greatly reducing the length of the token sequences. We show that the resulting model can be viewed as a learner over dynamic directed hypergraphs. And, we employ it to learn to compose expressive Pop piano music of full-song length (involving up to 10K individual tokens per song), both conditionally and unconditionally. Our experiment shows that, compared to state-of-the-art models, the proposed model converges 5 to 10 times faster at training (i.e., within a day on a single {GPU} with 11 {GB} memory), and with comparable quality in the generated music}
      \field{journaltitle}{Proceedings of the {AAAI} Conference on Artificial Intelligence}
      \field{note}{Number: 1}
      \field{number}{1}
      \field{title}{Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs}
      \field{volume}{35}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{pages}{178\bibrangedash 186}
      \range{pages}{9}
      \verb{file}
      \verb Full Text PDF:C\:\\Users\\oanou\\Zotero\\storage\\H5QMGZGY\\Hsiao et al. - 2021 - Compound Word Transformer Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs.pdf:application/pdf
      \endverb
      \keyw{Art/Music/Creativity}
    \endentry
    \entry{huang_pop_2020}{inproceedings}{}{}
      \name{author}{2}{}{%
        {{hash=cea28bfa1795079755eb7becc3c90966}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Yu-Siang},
           giveni={Y\bibinithyphendelim S\bibinitperiod}}}%
        {{hash=dc4d44f6814797864181d8ee2756517f}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Yi-Hsuan},
           giveni={Y\bibinithyphendelim H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, {NY}, {USA}}%
      }
      \list{publisher}{1}{%
        {Association for Computing Machinery}%
      }
      \strng{namehash}{914ef31345e0bc338408e854ab273106}
      \strng{fullhash}{914ef31345e0bc338408e854ab273106}
      \strng{fullhashraw}{914ef31345e0bc338408e854ab273106}
      \strng{bibnamehash}{914ef31345e0bc338408e854ab273106}
      \strng{authorbibnamehash}{914ef31345e0bc338408e854ab273106}
      \strng{authornamehash}{914ef31345e0bc338408e854ab273106}
      \strng{authorfullhash}{914ef31345e0bc338408e854ab273106}
      \strng{authorfullhashraw}{914ef31345e0bc338408e854ab273106}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A great number of deep learning based models have been recently proposed for automatic music composition. Among these models, the Transformer stands out as a prominent approach for generating expressive classical piano performance with a coherent structure of up to one minute. The model is powerful in that it learns abstractions of data on its own, without much human-imposed domain knowledge or constraints. In contrast with this general approach, this paper shows that Transformers can do even better for music modeling, when we improve the way a musical score is converted into the data fed to a Transformer model. In particular, we seek to impose a metrical structure in the input data, so that Transformers can be more easily aware of the beat-bar-phrase hierarchical structure in music. The new data representation maintains the flexibility of local tempo changes, and provides hurdles to control the rhythmic and harmonic structure of music. With this approach, we build a Pop Music Transformer that composes Pop piano music with better rhythmic structure than existing Transformer models.}
      \field{booktitle}{Proceedings of the 28th {ACM} International Conference on Multimedia}
      \field{series}{{MM} '20}
      \field{title}{Pop Music Transformer: Beat-based Modeling and Generation of Expressive Pop Piano Compositions}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{pages}{1180\bibrangedash 1188}
      \range{pages}{9}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\W8NBBAZU\\Huang et Yang - 2020 - Pop Music Transformer Beat-based Modeling and Generation of Expressive Pop Piano Compositions.pdf:application/pdf
      \endverb
    \endentry
    \entry{le_natural_2024}{misc}{}{}
      \name{author}{4}{}{%
        {{hash=7976c4abff6da9f3988931419e318561}{%
           family={Le},
           familyi={L\bibinitperiod},
           given={Dinh-Viet-Toan},
           giveni={D\bibinithyphendelim V\bibinithyphendelim T\bibinitperiod}}}%
        {{hash=e686bdd8fdd2a400c824e6aa9dd01ffd}{%
           family={Bigo},
           familyi={B\bibinitperiod},
           given={Louis},
           giveni={L\bibinitperiod}}}%
        {{hash=08610c5a12e8fb596e42cdd0068cb449}{%
           family={Keller},
           familyi={K\bibinitperiod},
           given={Mikaela},
           giveni={M\bibinitperiod}}}%
        {{hash=fdae87cad6eeb39b72cfdb074d296c7b}{%
           family={Herremans},
           familyi={H\bibinitperiod},
           given={Dorien},
           giveni={D\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{0104ae14344cea2ab4e025b86c7bf8e8}
      \strng{fullhash}{678b0dee4f56058c604adcdeaef01a4a}
      \strng{fullhashraw}{678b0dee4f56058c604adcdeaef01a4a}
      \strng{bibnamehash}{0104ae14344cea2ab4e025b86c7bf8e8}
      \strng{authorbibnamehash}{0104ae14344cea2ab4e025b86c7bf8e8}
      \strng{authornamehash}{0104ae14344cea2ab4e025b86c7bf8e8}
      \strng{authorfullhash}{678b0dee4f56058c604adcdeaef01a4a}
      \strng{authorfullhashraw}{678b0dee4f56058c604adcdeaef01a4a}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Several adaptations of Transformers models have been developed in various domains since its breakthrough in Natural Language Processing ({NLP}). This trend has spread into the field of Music Information Retrieval ({MIR}), including studies processing music data. However, the practice of leveraging {NLP} tools for symbolic music data is not novel in {MIR}. Music has been frequently compared to language, as they share several similarities, including sequential representations of text and music. These analogies are also reflected through similar tasks in {MIR} and {NLP}.}
      \field{title}{Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: a Survey}
      \field{year}{2024}
      \field{dateera}{ce}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\8MQPSZTE\\Le et al. - 2024 - Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval a Surve.pdf:application/pdf
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{makris_conditional_2022}{inproceedings}{}{}
      \name{author}{4}{}{%
        {{hash=0dcecc7736753302481ab34658ae61eb}{%
           family={Makris},
           familyi={M\bibinitperiod},
           given={Dimos},
           giveni={D\bibinitperiod}}}%
        {{hash=7a7d4c32b1ca2415bae5be7d6062c116}{%
           family={Zixun},
           familyi={Z\bibinitperiod},
           given={Guo},
           giveni={G\bibinitperiod}}}%
        {{hash=cf60dc5af6b4085aafab2f4d0837dc89}{%
           family={Kaliakatsos-Papakostas},
           familyi={K\bibinithyphendelim P\bibinitperiod},
           given={Maximos},
           giveni={M\bibinitperiod}}}%
        {{hash=fdae87cad6eeb39b72cfdb074d296c7b}{%
           family={Herremans},
           familyi={H\bibinitperiod},
           given={Dorien},
           giveni={D\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=f9cb873191e30a6faa58f343901d091f}{%
           family={Martins},
           familyi={M\bibinitperiod},
           given={Tiago},
           giveni={T\bibinitperiod}}}%
        {{hash=d4c92109cbe68b2384a9fc5ac45c2652}{%
           family={Rodríguez-Fernández},
           familyi={R\bibinithyphendelim F\bibinitperiod},
           given={Nereida},
           giveni={N\bibinitperiod}}}%
        {{hash=47ab044477e2c86a341f89a9391e737e}{%
           family={Rebelo},
           familyi={R\bibinitperiod},
           given={Sérgio\bibnamedelima M.},
           giveni={S\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Cham}%
      }
      \list{publisher}{1}{%
        {Springer International Publishing}%
      }
      \strng{namehash}{03627e7b0dfba239d43a948347e7b39a}
      \strng{fullhash}{bbeb6d591996232da3dfe65174d5a9c9}
      \strng{fullhashraw}{bbeb6d591996232da3dfe65174d5a9c9}
      \strng{bibnamehash}{03627e7b0dfba239d43a948347e7b39a}
      \strng{authorbibnamehash}{03627e7b0dfba239d43a948347e7b39a}
      \strng{authornamehash}{03627e7b0dfba239d43a948347e7b39a}
      \strng{authorfullhash}{bbeb6d591996232da3dfe65174d5a9c9}
      \strng{authorfullhashraw}{bbeb6d591996232da3dfe65174d5a9c9}
      \strng{editorbibnamehash}{bfc2490e4d6ad3aeae567e4f25f67b69}
      \strng{editornamehash}{bfc2490e4d6ad3aeae567e4f25f67b69}
      \strng{editorfullhash}{bfc2490e4d6ad3aeae567e4f25f67b69}
      \strng{editorfullhashraw}{bfc2490e4d6ad3aeae567e4f25f67b69}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The field of automatic music composition has seen great progress in recent years, specifically with the invention of transformer-based architectures. When using any deep learning model which considers music as a sequence of events with multiple complex dependencies, the selection of a proper data representation is crucial. In this paper, we tackle the task of conditional drums generation using a novel data encoding scheme inspired by the Compound Word representation, a tokenization process of sequential data. Therefore, we present a sequence-to-sequence architecture where a Bidirectional Long short-term memory ({BiLSTM}) Encoder receives information about the conditioning parameters (i.e., accompanying tracks and musical attributes), while a Transformer-based Decoder with relative global attention produces the generated drum sequences. We conducted experiments to thoroughly compare the effectiveness of our method to several baselines. Quantitative evaluation shows that our model is able to generate drums sequences that have similar statistical distributions and characteristics to the training corpus. These features include syncopation, compression ratio, and symmetry among others. We also verified, through a listening test, that generated drum sequences sound pleasant, natural and coherent while they “groove” with the given accompaniment.}
      \field{booktitle}{Artificial Intelligence in Music, Sound, Art and Design}
      \field{title}{Conditional Drums Generation Using Compound Word Representations}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{pages}{179\bibrangedash 194}
      \range{pages}{16}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\JIVK8KFX\\Makris et al. - 2022 - Conditional Drums Generation using Compound Word Representations.pdf:application/pdf
      \endverb
    \endentry
    \entry{raffel_learning-based_2016}{article}{}{}
      \name{author}{1}{}{%
        {{hash=81a5a94e2388c149a73a86381db45e07}{%
           family={Raffel},
           familyi={R\bibinitperiod},
           given={Colin},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{81a5a94e2388c149a73a86381db45e07}
      \strng{fullhash}{81a5a94e2388c149a73a86381db45e07}
      \strng{fullhashraw}{81a5a94e2388c149a73a86381db45e07}
      \strng{bibnamehash}{81a5a94e2388c149a73a86381db45e07}
      \strng{authorbibnamehash}{81a5a94e2388c149a73a86381db45e07}
      \strng{authornamehash}{81a5a94e2388c149a73a86381db45e07}
      \strng{authorfullhash}{81a5a94e2388c149a73a86381db45e07}
      \strng{authorfullhashraw}{81a5a94e2388c149a73a86381db45e07}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Learning-Based Methods for Comparing Sequences, with Applications to Audio-to-{MIDI} Alignment and Matching}
      \field{year}{2016}
      \field{dateera}{ce}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\2T7FTDDM\\Raffel - Learning-Based Methods for Comparing Sequences, with Applications to Audio-to-MIDI Alignment and Mat.pdf:application/pdf;The Lakh MIDI Dataset v0.1:C\:\\Users\\oanou\\Zotero\\storage\\C44UCVTT\\lmd.html:text/html
      \endverb
    \endentry
    \entry{regnier_identification_2021}{article}{}{}
      \name{author}{3}{}{%
        {{hash=2ea6af6736c402f1285975e79b3cb974}{%
           family={Régnier},
           familyi={R\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=0e114fcb893c9e96e896bc25a778900a}{%
           family={Martin},
           familyi={M\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
        {{hash=e686bdd8fdd2a400c824e6aa9dd01ffd}{%
           family={Bigo},
           familyi={B\bibinitperiod},
           given={Louis},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{ab01aa1771dbe9297fb4b44c632181b6}
      \strng{fullhash}{ab01aa1771dbe9297fb4b44c632181b6}
      \strng{fullhashraw}{ab01aa1771dbe9297fb4b44c632181b6}
      \strng{bibnamehash}{ab01aa1771dbe9297fb4b44c632181b6}
      \strng{authorbibnamehash}{ab01aa1771dbe9297fb4b44c632181b6}
      \strng{authornamehash}{ab01aa1771dbe9297fb4b44c632181b6}
      \strng{authorfullhash}{ab01aa1771dbe9297fb4b44c632181b6}
      \strng{authorfullhashraw}{ab01aa1771dbe9297fb4b44c632181b6}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sections of guitar parts in pop/rock songs are commonly described by functional terms including for example rhythm guitar, lead guitar, solo or riff. At a low level, these terms generally involve textural properties, for example whether the guitar tends to play chords or single notes. At a higher level, they indicate the function the guitar is playing relative to other instruments of the ensemble, for example whether the guitar is accompanying in background, or if it is intended to play a part in the foreground. Automatic labelling of instrumental function has various potential applications including the creation of consistent datasets dedicated to the training of generative models that focus on a particular function. In this paper, we propose a computational method to identify rhythm guitar sections in symbolic tablatures. We deﬁne rhythm guitar as sections that aim at making the listener perceive the chord progression that characterizes the harmony part of the song. A set of 31 high level features is proposed to predict if a bar in a tablature should be labeled as rhythm guitar or not. These features are used by an {LSTM} classiﬁer which yields to a F1 score of 0.95 on a dataset of 102 guitar tablatures with manual function annotations. Manual annotations and computed feature vectors are publicly released.}
      \field{title}{Identification of rhythm guitar sections in symbolic tablatures}
      \field{year}{2021}
      \field{dateera}{ce}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\B4QVCY89\\Régnier et al. - 2021 - IDENTIFICATION OF RHYTHM GUITAR SECTIONS IN SYMBOLIC TABLATURES.pdf:application/pdf
      \endverb
    \endentry
    \entry{sarmento_dadagp_2021}{inproceedings}{}{}
      \name{author}{6}{}{%
        {{hash=92b0f740116fd980c08930a1eaa0e802}{%
           family={Sarmento},
           familyi={S\bibinitperiod},
           given={Pedro},
           giveni={P\bibinitperiod}}}%
        {{hash=3bd7ae2c44e397de05de5ab18c5b9cfd}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Adarsh},
           giveni={A\bibinitperiod}}}%
        {{hash=cb903dfbc927197d691400664efa87c2}{%
           family={Carr},
           familyi={C\bibinitperiod},
           given={CJ},
           giveni={C\bibinitperiod}}}%
        {{hash=9ffab4bbffdcaebb4bb6d39b39ef88d3}{%
           family={Zukowski},
           familyi={Z\bibinitperiod},
           given={Zack},
           giveni={Z\bibinitperiod}}}%
        {{hash=018cf62bd03e53ac67d841ba16d42c85}{%
           family={Barthet},
           familyi={B\bibinitperiod},
           given={Mathieu},
           giveni={M\bibinitperiod}}}%
        {{hash=dc4d44f6814797864181d8ee2756517f}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Yi-Hsuan},
           giveni={Y\bibinithyphendelim H\bibinitperiod}}}%
      }
      \strng{namehash}{7905da357777d423391c8ce1ce35994d}
      \strng{fullhash}{21e879e8ce21b3d38e22df55df035e11}
      \strng{fullhashraw}{21e879e8ce21b3d38e22df55df035e11}
      \strng{bibnamehash}{7905da357777d423391c8ce1ce35994d}
      \strng{authorbibnamehash}{7905da357777d423391c8ce1ce35994d}
      \strng{authornamehash}{7905da357777d423391c8ce1ce35994d}
      \strng{authorfullhash}{21e879e8ce21b3d38e22df55df035e11}
      \strng{authorfullhashraw}{21e879e8ce21b3d38e22df55df035e11}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the 22nd International Society for Music Information Retrieval Conference}
      \field{title}{{DadaGP: a Dataset of Tokenized GuitarPro Songs for Sequence Models}}
      \field{year}{2021}
      \verb{urlraw}
      \verb https://archives.ismir.net/ismir2021/paper/000076.pdf
      \endverb
      \verb{url}
      \verb https://archives.ismir.net/ismir2021/paper/000076.pdf
      \endverb
    \endentry
    \entry{sarmento_gtr-ctrl_2023}{inproceedings}{}{}
      \name{author}{6}{}{%
        {{hash=92b0f740116fd980c08930a1eaa0e802}{%
           family={Sarmento},
           familyi={S\bibinitperiod},
           given={Pedro},
           giveni={P\bibinitperiod}}}%
        {{hash=3bd7ae2c44e397de05de5ab18c5b9cfd}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Adarsh},
           giveni={A\bibinitperiod}}}%
        {{hash=4cbd9d2fc19a7e8acb2ed7f7dbb95156}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Yu-Hua},
           giveni={Y\bibinithyphendelim H\bibinitperiod}}}%
        {{hash=cb903dfbc927197d691400664efa87c2}{%
           family={Carr},
           familyi={C\bibinitperiod},
           given={{CJ}},
           giveni={C\bibinitperiod}}}%
        {{hash=9ffab4bbffdcaebb4bb6d39b39ef88d3}{%
           family={Zukowski},
           familyi={Z\bibinitperiod},
           given={Zack},
           giveni={Z\bibinitperiod}}}%
        {{hash=018cf62bd03e53ac67d841ba16d42c85}{%
           family={Barthet},
           familyi={B\bibinitperiod},
           given={Mathieu},
           giveni={M\bibinitperiod}}}%
      }
      \name{editor}{3}{}{%
        {{hash=9ef0cac2a11ccca1d0ea584013de07db}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Colin},
           giveni={C\bibinitperiod}}}%
        {{hash=d4c92109cbe68b2384a9fc5ac45c2652}{%
           family={Rodríguez-Fernández},
           familyi={R\bibinithyphendelim F\bibinitperiod},
           given={Nereida},
           giveni={N\bibinitperiod}}}%
        {{hash=47ab044477e2c86a341f89a9391e737e}{%
           family={Rebelo},
           familyi={R\bibinitperiod},
           given={Sérgio\bibnamedelima M.},
           giveni={S\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer Nature Switzerland}%
      }
      \strng{namehash}{7905da357777d423391c8ce1ce35994d}
      \strng{fullhash}{638c7581c14983e74efab4a21c237341}
      \strng{fullhashraw}{638c7581c14983e74efab4a21c237341}
      \strng{bibnamehash}{7905da357777d423391c8ce1ce35994d}
      \strng{authorbibnamehash}{7905da357777d423391c8ce1ce35994d}
      \strng{authornamehash}{7905da357777d423391c8ce1ce35994d}
      \strng{authorfullhash}{638c7581c14983e74efab4a21c237341}
      \strng{authorfullhashraw}{638c7581c14983e74efab4a21c237341}
      \strng{editorbibnamehash}{878bea7ebf973f0fb2b99a24f2e63e4a}
      \strng{editornamehash}{878bea7ebf973f0fb2b99a24f2e63e4a}
      \strng{editorfullhash}{878bea7ebf973f0fb2b99a24f2e63e4a}
      \strng{editorfullhashraw}{878bea7ebf973f0fb2b99a24f2e63e4a}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Recently, symbolic music generation with deep learning techniques has witnessed steady improvements. Most works on this topic focus on {MIDI} representations, but less attention has been paid to symbolic music generation using guitar tablatures (tabs) which can be used to encode multiple instruments. Tabs include information on expressive techniques and fingerings for fretted string instruments in addition to rhythm and pitch. In this work, we use the {DadaGP} dataset for guitar tab music generation, a corpus of over 26k songs in {GuitarPro} and token formats. We introduce methods to condition a Transformer-{XL} deep learning model to generate guitar tabs ({GTR}-{CTRL}) based on desired instrumentation (inst-{CTRL}) and genre (genre-{CTRL}). Special control tokens are appended at the beginning of each song in the training corpus. We assess the performance of the model with and without conditioning. We propose instrument presence metrics to assess the inst-{CTRL} model’s response to a given instrumentation prompt. We trained a {BERT} model for downstream genre classification and used it to assess the results obtained with the genre-{CTRL} model. Statistical analyses evidence significant differences between the conditioned and unconditioned models. Overall, results indicate that the {GTR}-{CTRL} methods provide more flexibility and control for guitar-focused symbolic music generation than an unconditioned model.}
      \field{booktitle}{Artificial Intelligence in Music, Sound, Art and Design}
      \field{shorttitle}{{GTR}-{CTRL}}
      \field{title}{{GTR}-{CTRL}: Instrument and Genre Conditioning for Guitar-Focused Music Generation with Transformers}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{pages}{260\bibrangedash 275}
      \range{pages}{16}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\9SDVXFNM\\Sarmento et al. - 2023 - GTR-CTRL Instrument and Genre Conditioning for Guitar-Focused Music Generation with Transformers.pdf:application/pdf
      \endverb
    \endentry
    \entry{vaswani_attention_2017}{inproceedings}{}{}
      \name{author}{8}{}{%
        {{hash=7f28e84700536646dd6620a0db07ad09}{%
           family={Vaswani},
           familyi={V\bibinitperiod},
           given={Ashish},
           giveni={A\bibinitperiod}}}%
        {{hash=62efade83d70f0323fe248755e6c90c5}{%
           family={Shazeer},
           familyi={S\bibinitperiod},
           given={Noam},
           giveni={N\bibinitperiod}}}%
        {{hash=06649ebab1ea5cac0250746a19764975}{%
           family={Parmar},
           familyi={P\bibinitperiod},
           given={Niki},
           giveni={N\bibinitperiod}}}%
        {{hash=831027ee0ebf22375e2a86afc1881909}{%
           family={Uszkoreit},
           familyi={U\bibinitperiod},
           given={Jakob},
           giveni={J\bibinitperiod}}}%
        {{hash=2fd2982e30ebcec93ec1cf76e0d797fd}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={Llion},
           giveni={L\bibinitperiod}}}%
        {{hash=27b07e4eacbf4ef7a1438e3badb7dd8d}{%
           family={Gomez},
           familyi={G\bibinitperiod},
           given={Aidan\bibnamedelima N},
           giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=540fcd72e1fa4bbed46604f4e6cff817}{%
           family={Kaiser},
           familyi={K\bibinitperiod},
           given={Ł\bibnamedelima ukasz},
           giveni={Ł\bibinitperiod\bibinitdelim u\bibinitperiod}}}%
        {{hash=95595a0fefb86187cbc36e551017d332}{%
           family={Polosukhin},
           familyi={P\bibinitperiod},
           given={Illia},
           giveni={I\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{fullhash}{cb26e47f6b8133865271fc8483132297}
      \strng{fullhashraw}{cb26e47f6b8133865271fc8483132297}
      \strng{bibnamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authorbibnamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authornamehash}{ee273ab30cfb889666f8c4d806eb9ce7}
      \strng{authorfullhash}{cb26e47f6b8133865271fc8483132297}
      \strng{authorfullhashraw}{cb26e47f6b8133865271fc8483132297}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 {BLEU} {onEnglish}-to-German translation, improving over the existing best ensemble result by over 1 {BLEU}. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 {BLEU}, achieving a {BLEU} score of 41.1.}
      \field{booktitle}{Advances in Neural Information Processing Systems}
      \field{title}{Attention is All you Need}
      \field{volume}{30}
      \field{year}{2017}
      \field{dateera}{ce}
      \verb{file}
      \verb Full Text PDF:C\:\\Users\\oanou\\Zotero\\storage\\VI69WRTP\\Vaswani et al. - 2017 - Attention is All you Need.pdf:application/pdf
      \endverb
    \endentry
    \entry{xi_guitarset_2018}{article}{}{}
      \name{author}{5}{}{%
        {{hash=7bfad8fa70441669cd1c81b13d75a48e}{%
           family={Xi},
           familyi={X\bibinitperiod},
           given={Qingyang},
           giveni={Q\bibinitperiod}}}%
        {{hash=2256a3179651b8216ff29de177a6de3d}{%
           family={Bittner},
           familyi={B\bibinitperiod},
           given={Rachel\bibnamedelima M},
           giveni={R\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=6dd052816f3ae210a6f0d47c431e2386}{%
           family={Pauwels},
           familyi={P\bibinitperiod},
           given={Johan},
           giveni={J\bibinitperiod}}}%
        {{hash=e31149edcd2fc3e9872f05357741b8ea}{%
           family={Ye},
           familyi={Y\bibinitperiod},
           given={Xuzhou},
           giveni={X\bibinitperiod}}}%
        {{hash=449fce9e1c2043d6dbf129f5c39f948a}{%
           family={Bello},
           familyi={B\bibinitperiod},
           given={Juan\bibnamedelima P},
           giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
      }
      \strng{namehash}{53f3af35ca598a30d7ceaa8736dd56d9}
      \strng{fullhash}{c7b0dc2273584892bd6e339fa7248e67}
      \strng{fullhashraw}{c7b0dc2273584892bd6e339fa7248e67}
      \strng{bibnamehash}{53f3af35ca598a30d7ceaa8736dd56d9}
      \strng{authorbibnamehash}{53f3af35ca598a30d7ceaa8736dd56d9}
      \strng{authornamehash}{53f3af35ca598a30d7ceaa8736dd56d9}
      \strng{authorfullhash}{c7b0dc2273584892bd6e339fa7248e67}
      \strng{authorfullhashraw}{c7b0dc2273584892bd6e339fa7248e67}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The guitar is a popular instrument for a variety of reasons, including its ability to produce polyphonic sound and its musical versatility. The resulting variability of sounds, however, poses signiﬁcant challenges to automated methods for analyzing guitar recordings. As data driven methods become increasingly popular for difﬁcult problems like guitar transcription, sets of labeled audio data are highly valuable resources. In this paper we present {GuitarSet}, a dataset that provides high quality guitar recordings alongside rich annotations and metadata. In particular, by recording guitars using a hexaphonic pickup, we are able to not only provide recordings of the individual strings but also to largely automate the expensive annotation process. The dataset contains recordings of a variety of musical excerpts played on an acoustic guitar, along with time-aligned annotations of string and fret positions, chords, beats, downbeats, and playing style. We conclude with an analysis of new challenges presented by this data, and see that it is interesting for a wide variety of tasks in addition to guitar transcription, including performance analysis, beat/downbeat tracking, and chord estimation.}
      \field{title}{​Guitarset: A Dataset for Guitar Transcription}
      \field{year}{2018}
      \field{dateera}{ce}
      \verb{file}
      \verb PDF:C\:\\Users\\oanou\\Zotero\\storage\\9HSHHK65\\Xi et al. - GUITARSET A DATASET FOR GUITAR TRANSCRIPTION.pdf:application/pdf
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

