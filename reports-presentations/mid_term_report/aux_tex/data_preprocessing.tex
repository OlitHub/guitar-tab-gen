% What we have done (data preprocessing, getting the rhythmic instrument, retrieving the tokens, baseline using dadagp (GuitarCTRL))
% --> Retrieving, cleaning, mapping DadaGP
% Rhythmic guitar detection (cite paper)

The DadaGP dataset provides token files containing information for all instruments in a score.
To explore various conditioning combinations for tablature generation, we developed a function to extract tokens specific to selected instruments.
Among these, we focused on conditioning bass guitar tablature generation using the rhythmic guitar.
% MORE DETAILS + FIG OF A TOKEN LIST WITH ALL INSTRUMENTS AND EXTRACTION OF A SINGLE INSTRUMENT
% TIME NEEDED TO PROCESS THE DATA
In typical rock band instrumentation, rhythmic guitars complement bass guitars with their repetitive chord patterns, providing harmonic and rhythmic structure at a higher pitch \cite{regnier_identification_2021}.
This characteristic makes them particularly relevant for conditioning bass generation tasks.

To identify rhythmic guitar parts in the DadaGP dataset, we implemented the identification method proposed by RÃ©gnier et al. \cite{regnier_identification_2021}, which uses features describing notes and chords at the bar level, along with corresponding tablatures.
Implementing this method required adapting their code to the DadaGP dataset.
Significant effort was spent mapping the identified rhythmic guitar parts to their respective names in the DadaGP files, as the dataset renames instruments, whereas the identification tool relies on GuitarPro part names.


\section{Baseline predictions}

With the preprocessed data, we began by establishing a baseline model for bass guitar tablature generation.
Initially, we utilized a pre-trained checkpoint from the DadaGP paper \cite{sarmento_dadagp_2021} without additional training.

% FIGURE REPETITIVE GENERATION

To generate bass-specific outputs, we experimented with various prompts.
First, we provided a single bass guitar note as the initial token.
However, the model quickly incorporated tokens from other instruments.
To constrain the output to bass tokens, we modified the logits of non-bass instruments by setting them to $-\infty$.
While this forced the model to generate only bass tokens, the output quality was poor, featuring repetitive phrases, harmonically incorrect notes, or complete aberrations.
This was expected, as the model was not trained explicitly for bass generation.
% LINK WITH THE ISSUES THEY ENCOUNTERED IN GTR CTRL

\section{Workplan}
% Workplan (what we are going to do)

% DETAILS
Our next steps include:
\begin{enumerate}
    \item Adapt and apply the model proposed by Makris et al. to the same task, with conditional information from several combinations of instruments.
    \item Evaluate the results using both human evaluation and numerical metrics. 
    \begin{itemize}
        \item Develop appropriate numerical metrics to quantify performance.
    \end{itemize}
\end{enumerate}