{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pickle5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle5\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pickle5'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# import tensorflow as tf\n",
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from aux_train_tf import HybridTransformer, create_masks\n",
    "\n",
    "# physical_devices = tf.config.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data from pre-processing\n",
    "train_path = 'train_set_streams.pickle'\n",
    "test_path = 'test_set_streams_pickle5.pickle'\n",
    "preprocessed_path = 'preprocessed_dataset.pickle'\n",
    "\n",
    "# with open(train_path, 'rb') as handle:\n",
    "#     trainSet = pickle.load(handle)\n",
    "\n",
    "with open(test_path, 'rb') as handle:\n",
    "    testSet = pickle.load(handle)\n",
    "    \n",
    "with open(preprocessed_path, 'rb') as handle:\n",
    "\tpreprocessed = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "# enc_inputO_train = np.int64(np.stack(trainSet['EncoderO_Input'])) #encoder Onset input\n",
    "# enc_inputG_train = np.int64(np.stack(trainSet['EncoderG_Input'])) #encoder Group input\n",
    "# enc_inputT_train = np.int64(np.stack(trainSet['EncoderT_Input'])) #encoder Type input\n",
    "# enc_inputD_train = np.int64(np.stack(trainSet['EncoderD_Input'])) #encoder Duration input\n",
    "# enc_inputV_train = np.int64(np.stack(trainSet['EncoderV_Input'])) #encoder Valueinput\n",
    "# dec_inputO_train = np.int64(np.stack(trainSet['DecoderO_Input'])) #decoder onset stream\n",
    "# dec_outputO_train = np.int64(np.stack(trainSet['DecoderO_Output']))\n",
    "# dec_inputD_train = np.int64(np.stack(trainSet['DecoderD_Input'])) #decoder drums stream\n",
    "# dec_outputD_train = np.int64(np.stack(trainSet['DecoderD_Output']))\n",
    "#validation\n",
    "enc_inputO_val = np.int64(np.stack(testSet['EncoderO_Input']))\n",
    "enc_inputG_val = np.int64(np.stack(testSet['EncoderG_Input']))\n",
    "enc_inputT_val = np.int64(np.stack(testSet['EncoderT_Input']))\n",
    "enc_inputD_val = np.int64(np.stack(testSet['EncoderD_Input']))\n",
    "enc_inputV_val = np.int64(np.stack(testSet['EncoderV_Input']))\n",
    "dec_inputO_val = np.int64(np.stack(testSet['DecoderO_Input']))\n",
    "dec_outputO_val = np.int64(np.stack(testSet['DecoderO_Output']))\n",
    "dec_inputD_val = np.int64(np.stack(testSet['DecoderD_Input']))\n",
    "dec_outputD_val = np.int64(np.stack(testSet['DecoderD_Output']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['All_Events', 'EncoderO_Input', 'EncoderG_Input', 'EncoderT_Input', 'EncoderD_Input', 'EncoderV_Input', 'DecoderO_Input', 'DecoderO_Output', 'DecoderD_Input', 'DecoderD_Output']),\n",
       " dict_keys(['All_events', 'Encoder_Onset', 'Encoder_Group', 'Encoder_Type', 'Encoder_Duration', 'Encoder_Value', 'Decoder_Onset', 'Decoder_Drums']))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet.keys(), preprocessed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('on_3.0', 'Guitar', 'Note', 'du_1.0', 'NaN')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 8\n",
    "\n",
    "preprocessed['Encoder_Onset'][0][i], preprocessed['Encoder_Group'][0][i], preprocessed['Encoder_Type'][0][i], preprocessed['Encoder_Duration'][0][i], preprocessed['Encoder_Value'][0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtestSet\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncoderO_Input\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;66;03m#[i]#, testSet['EncoderG_Input'][i], testSet['EncoderT_Input'][i], testSet['EncoderD_Input'][i], testSet['EncoderV_Input'][i]\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testSet' is not defined"
     ]
    }
   ],
   "source": [
    "testSet['EncoderO_Input'][i]#, testSet['EncoderG_Input'][i], testSet['EncoderT_Input'][i], testSet['EncoderD_Input'][i], testSet['EncoderV_Input'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prepare datasets\n",
    "BUFFER_SIZE = len(enc_inputO_val)\n",
    "BUFFER_SIZE_EVAL = len(enc_inputO_val)\n",
    "BATCH_SIZE = 32 #set batch size\n",
    "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
    "steps_per_epoch_eval = BUFFER_SIZE_EVAL//BATCH_SIZE\n",
    "\n",
    "#create training and evaluation tf dataset\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((enc_inputO_train, enc_inputG_train, enc_inputT_train, \n",
    "#                                               enc_inputD_train, enc_inputV_train,\n",
    "#                                               dec_inputO_train, dec_outputO_train,\n",
    "#                                               dec_inputD_train, dec_outputD_train)).shuffle(BUFFER_SIZE)\n",
    "# dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_eval = tf.data.Dataset.from_tensor_slices((enc_inputO_val, enc_inputG_val, enc_inputT_val, \n",
    "                                                   enc_inputD_val, enc_inputV_val,\n",
    "                                                   dec_inputO_val, dec_outputO_val,\n",
    "                                                   dec_inputD_val, dec_outputD_val)).shuffle(BUFFER_SIZE_EVAL)\n",
    "dataset_eval = dataset_eval.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "\n",
    "#set transformer hyper parameters\n",
    "num_layers = 4  #attention layers\n",
    "#Embeddings\n",
    "d_model_enc1 = 64 #Encoder Onset\n",
    "d_model_enc2 = 16 #Encoder Instrument\n",
    "d_model_enc3 = 32 #Encoder Type\n",
    "d_model_enc4 = 64 #Encoder Duration \n",
    "d_model_enc5 = 64 #Encoder Value \n",
    "\n",
    "d_model_dec1 = 96 #Decoder Onset Embedding\n",
    "d_model_dec2 = 96 #Decoder Drums Embedding\n",
    "\n",
    "units = 1024 #for Dense Layers and BLSTM Encoder\n",
    "num_heads = 8 #\n",
    "dropout_rate = 0.3\n",
    "epochs = 200 \n",
    "#vocab sizes\n",
    "enc_vocab_onsets = 31\n",
    "enc_vocab_group = 5\n",
    "enc_vocab_type = 7\n",
    "enc_vocab_dur = 40\n",
    "enc_vocab_value = 33\n",
    "\n",
    "dec_vocab_onsets = 31\n",
    "dec_vocab_drums = 16\n",
    "#sequence lengths\n",
    "enc_seq_length = 597\n",
    "dec_seq_length = 545\n",
    "#for relative attention half or full window\n",
    "rel_dec_seq = dec_seq_length\n",
    "\n",
    "model = HybridTransformer(num_layers=num_layers, d_model_enc1=d_model_enc1, d_model_enc2=d_model_enc2, \n",
    "                          d_model_enc3=d_model_enc3, d_model_enc4=d_model_enc4, d_model_enc5=d_model_enc5, \n",
    "                          d_model_dec1=d_model_dec1, d_model_dec2=d_model_dec2, num_heads=num_heads,\n",
    "                          dff=units, input_vocab1=enc_vocab_onsets+1, input_vocab2=enc_vocab_group+1, \n",
    "                          input_vocab3=enc_vocab_type+1, input_vocab4=enc_vocab_dur+1, \n",
    "                          input_vocab5=enc_vocab_value+1, target_vocab1=dec_vocab_onsets+1, \n",
    "                          target_vocab2=dec_vocab_drums+1,pe_target=dec_seq_length, \n",
    "                          mode_choice='relative', #change to multihead for vanilla attention mechanism\n",
    "                          max_rel_pos_tar=rel_dec_seq, rate=dropout_rate)\n",
    "\n",
    "\n",
    "\n",
    "#Set Optimizers and Loss Function\n",
    "optimizer = tf.keras.optimizers.Adam(0.0005, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction='none')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(32, 597), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(32, 597), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(32, 597), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(32, 597), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(32, 597), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(32, 545), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(32, 545), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(32, 545), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(32, 545), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eval.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "#Set TF Metrics\n",
    "train_loss_onsets = tf.keras.metrics.Mean(name='train_loss_onsets')\n",
    "train_accuracy_onsets = tf.keras.metrics.Mean(name='train_accuracy_onsets')\n",
    "train_loss_drums = tf.keras.metrics.Mean(name='train_loss_drums')\n",
    "train_accuracy_drums = tf.keras.metrics.Mean(name='train_accuracy_drums')\n",
    "\n",
    "val_loss_onsets = tf.keras.metrics.Mean(name='val_loss_onsets')\n",
    "val_accuracy_onsets = tf.keras.metrics.Mean(name='val_accuracy_onsets')\n",
    "val_loss_drums = tf.keras.metrics.Mean(name='val_loss_drums')\n",
    "val_accuracy_drums = tf.keras.metrics.Mean(name='val_accuracy_drums')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Set Checkpoints\n",
    "\n",
    "checkpoint_path = './checkpoints/'\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print('Latest checkpoint restored!!')\n",
    "  \n",
    "  \n",
    "\n",
    "# Set input signatures\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64)\n",
    "]\n",
    "\n",
    "val_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Training and Validation functions'''\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp1, inp2, inp3, inp4, inp5, tar_inp1, tar_real1, \n",
    "               tar_inp2, tar_real2):\n",
    "\n",
    "  _, combined_mask, dec_padding_mask = create_masks(inp1, tar_inp1)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    preds1, preds2, _ = model(inp1, inp2, inp3, inp4, inp5, \n",
    "                              tar_inp1, tar_inp2,\n",
    "                              True,\n",
    "                              combined_mask,\n",
    "                              dec_padding_mask)\n",
    "    \n",
    "    loss1 = loss_function(tar_real1, preds1)\n",
    "    loss2 = loss_function(tar_real2, preds2)\n",
    "    loss = 0.5*loss1+0.5*loss2 #equal loss\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  \n",
    "  acc1 = accuracy_function(tar_real1, preds1)\n",
    "  acc2 = accuracy_function(tar_real2, preds2)\n",
    "\n",
    "  train_loss_onsets(loss1)\n",
    "  train_loss_drums(loss2)\n",
    "  train_accuracy_onsets(acc1)\n",
    "  train_accuracy_drums(acc2)\n",
    "  \n",
    "  \n",
    "  \n",
    "@tf.function(input_signature=val_step_signature)\n",
    "def val_step(inp1, inp2, inp3, inp4, inp5, tar_inp1, tar_real1, \n",
    "               tar_inp2, tar_real2):\n",
    "\n",
    "\n",
    "  _, combined_mask, dec_padding_mask = create_masks(inp1, tar_inp1)\n",
    "\n",
    "  preds1, preds2, _ = model(inp1, inp2, inp3, inp4, inp5, \n",
    "                            tar_inp1, tar_inp2,\n",
    "                            False, #change?\n",
    "                            combined_mask,\n",
    "                            dec_padding_mask)\n",
    "  \n",
    "  loss1 = loss_function(tar_real1, preds1)\n",
    "  loss2 = loss_function(tar_real2, preds2)\n",
    "  \n",
    "  acc1 = accuracy_function(tar_real1, preds1)\n",
    "  acc2 = accuracy_function(tar_real2, preds2)\n",
    "\n",
    "  val_loss_onsets(loss1)\n",
    "  val_loss_drums(loss2)\n",
    "  val_accuracy_onsets(acc1)\n",
    "  val_accuracy_drums(acc2)\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\"\"\"START TRAINING\"\"\"\n",
    "patience = 0\n",
    "curr_loss = 99.99    \n",
    "for epoch in range(epochs):\n",
    "  start = time.time()\n",
    "\n",
    "  train_loss_onsets.reset_states()\n",
    "  train_accuracy_onsets.reset_states()\n",
    "  train_loss_drums.reset_states()\n",
    "  train_accuracy_drums.reset_states()\n",
    "  \n",
    "  print(f'Epoch {epoch + 1}')\n",
    "  print('----')\n",
    "  for (batch, (inp1, inp2, inp3, inp4, inp5, tar_inp1, tar_real1, \n",
    "               tar_inp2, tar_real2)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    train_step(inp1, inp2, inp3, inp4, inp5, \n",
    "               tar_inp1, tar_real1, tar_inp2, tar_real2)\n",
    "\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print(f'Batch {batch}')\n",
    "      print(f'Onset Loss {train_loss_onsets.result():.4f} -- Onset Accuracy {train_accuracy_onsets.result():.4f}')\n",
    "      print(f'Drums Loss {train_loss_drums.result():.4f} -- Drums Accuracy {train_accuracy_drums.result():.4f}')\n",
    "\n",
    "  print('----')\n",
    "  print(f'Onset Loss {train_loss_onsets.result():.4f} -- Onset Accuracy {train_accuracy_onsets.result():.4f}')\n",
    "  print(f'Drums Loss {train_loss_drums.result():.4f} -- Drums Accuracy {train_accuracy_drums.result():.4f}')\n",
    "  \n",
    "  \n",
    "  print('Evaluating...')\n",
    "\n",
    "  val_loss_onsets.reset_states()\n",
    "  val_accuracy_onsets.reset_states()  \n",
    "  val_loss_drums.reset_states()\n",
    "  val_accuracy_drums.reset_states()  \n",
    "  \n",
    "  for (batch, (inp1, inp2, inp3, inp4, inp5, tar_inp1, tar_real1, \n",
    "               tar_inp2, tar_real2)) in enumerate(dataset_eval.take(steps_per_epoch_eval)):\n",
    "    val_step(inp1, inp2, inp3, inp4, inp5, \n",
    "             tar_inp1, tar_real1, tar_inp2, tar_real2)\n",
    "  \n",
    "  print('----')\n",
    "  print(f'Validation Onset Loss {val_loss_onsets.result():.4f} -- Onset Accuracy {val_accuracy_onsets.result():.4f}')  \n",
    "  print(f'Validation Drums Loss {val_loss_drums.result():.4f} -- Drums Accuracy {val_accuracy_drums.result():.4f}')  \n",
    "  \n",
    "  val_loss = np.round((0.5*val_loss_onsets.result().numpy() + 0.5*val_loss_drums.result().numpy()), decimals = 5) #change weights\n",
    "  print('Overall weighted Validation Loss: ', val_loss)\n",
    "  \n",
    "  '''EARLY STOP MECHANISM'''\n",
    "  if curr_loss > val_loss:\n",
    "    #save checkpoint\n",
    "    print('Checkpoint saved.')\n",
    "    patience = 0\n",
    "    save_path = ckpt_manager.save()\n",
    "    curr_loss = val_loss\n",
    "    \n",
    "  else:\n",
    "      print('No validation loss improvement.')\n",
    "      patience += 1\n",
    "      \n",
    "  print(f'Time taken for this epoch: {time.time() - start:.2f} secs\\n')    \n",
    "  print('*******************************')\n",
    "      \n",
    "  if patience > 5:\n",
    "      print('Terminating the training.')\n",
    "      break\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
