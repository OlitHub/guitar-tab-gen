{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Import the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to reload all modules (except those excluded by %aimport)\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for GPU inference\n",
    "from glob import glob\n",
    "import pickle5 as pickle\n",
    "import pretty_midi as pm\n",
    "from gen_utils import bass_trans_ev_model_tf, generate_bass_ev_trans_tf, create_enc, create_onehot_enc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_measures = 16\n",
    "thr_max_tokens = 800\n",
    "thr_min_tokens = 50\n",
    "dec_seq_length = 793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load Encoders pickle for onehotencoders'''\n",
    "\n",
    "#encoders pickle is created during pre-processing\n",
    "encoders_trans = './aux_files/bass_encoders_cp.pickle'\n",
    "\n",
    "    \n",
    "with open(encoders_trans, 'rb') as handle:\n",
    "    TransEncoders = pickle.load(handle)\n",
    "#[Encoder_RG, Decoder_Bass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hybrid Music Transformer\n",
      "Latest checkpoint restored!\n"
     ]
    }
   ],
   "source": [
    "'''Load Inference Transformer. You may download pre-trained model based \n",
    "on the paper. See instructions in ReadME.md'''\n",
    "trans_bass_hb = bass_trans_ev_model_tf(TransEncoders) \n",
    "\n",
    "\n",
    "'''Set Temperature'''\n",
    "temperature = 0.9\n",
    "\n",
    "'''Load MIDI files with Guitar (1st) and Bass (2nd). See examples in midi_in folder'''\n",
    "'''max 16 bars'''\n",
    "#input folder (put txt token files of rg only here)\n",
    "inp_path = glob('./tokens_in/*.txt')\n",
    "#output folder\n",
    "out_path = './tokens_out/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating.. Metallica - Enter Sandman (5)_rythmic\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"relative_global_attention_3\" \"                 f\"(type RelativeGlobalAttention).\n\nReceived incompatible tensor with shape (793, 24) when attempting to restore variable with shape (545, 24) and name model/decoder/dec_layers/1/attn2/relative_embeddings/.ATTRIBUTES/VARIABLE_VALUE.\n\nCall arguments received by layer \"relative_global_attention_3\" \"                 f\"(type RelativeGlobalAttention):\n  • v=tf.Tensor(shape=(1, 263, 1024), dtype=float32)\n  • k=tf.Tensor(shape=(1, 263, 1024), dtype=float32)\n  • q=tf.Tensor(shape=(1, 1, 192), dtype=float32)\n  • mask=tf.Tensor(shape=(1, 1, 1, 263), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10708\\3650021871.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# call generation functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mbass_HB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_bass_ev_trans_tf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans_bass_hb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransEncoders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEnc_Input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_seq_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdec_seq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m# save token files to be passed to the tokens2gp5 algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtrk_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\gen_utils.py\u001b[0m in \u001b[0;36mgenerate_bass_ev_trans_tf\u001b[1;34m(trans_bass, TransEncoders, temperature, Encoder_RG, dec_seq_length)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m        preds_onsets, preds_bass, _ = trans_bass(Encoder_RG, dec_out_bass, \n\u001b[1;32m--> 130\u001b[1;33m                                                    combined_mask, dec_padding_mask, training=False)\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m        \u001b[1;31m#Onset out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\CP_DRUMS\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\aux_files\\aux_train_tf.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inp, tar, look_ahead_mask, dec_padding_mask, training)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     dec_output, attention_weights = self.decoder(\n\u001b[1;32m--> 447\u001b[1;33m         tar, enc_output, look_ahead_mask, dec_padding_mask, training=training)\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[0mfinal_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_layer_tar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (batch_size, tar_seq_len, target_vocab1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\aux_files\\aux_train_tf.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, enc_output, look_ahead_mask, padding_mask, training)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m       x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask=look_ahead_mask,\n\u001b[1;32m--> 357\u001b[1;33m                                              padding_mask=padding_mask, training=training)\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\aux_files\\aux_train_tf.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, enc_output, look_ahead_mask, padding_mask, training)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mattn1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mout1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mattn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_weights_block2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (batch_size, target_seq_len, d_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[0mattn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mout2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayernorm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattn2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mout1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (batch_size, target_seq_len, d_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\aux_files\\aux_train_tf.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, v, k, q, mask)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (batch_size, num_heads, seq_len_v, depth)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[0mattention\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelative_global_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[0mconcat_attention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\aux_files\\aux_train_tf.py\u001b[0m in \u001b[0;36mrelative_global_attn\u001b[1;34m(self, q, k, v, mask)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mlen_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_left_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_q\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# in the t2t version it uses len_k, but it assumes len_q == len_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[0mQE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bhld,md->bhlm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# print(f\"E shape: {E.shape}, E: {E}, QE shape:{QE.shape}, QE:{QE}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\aux_files\\aux_train_tf.py\u001b[0m in \u001b[0;36m_get_left_embedding\u001b[1;34m(self, length)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             self.relative_embeddings = tf.Variable(name=\"relative_embedding\", \n\u001b[1;32m--> 207\u001b[1;33m                     initial_value=tf.random_normal_initializer(stddev=initializer_stddev)(shape=embedding_shape))\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mpad_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_relative_position\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"relative_global_attention_3\" \"                 f\"(type RelativeGlobalAttention).\n\nReceived incompatible tensor with shape (793, 24) when attempting to restore variable with shape (545, 24) and name model/decoder/dec_layers/1/attn2/relative_embeddings/.ATTRIBUTES/VARIABLE_VALUE.\n\nCall arguments received by layer \"relative_global_attention_3\" \"                 f\"(type RelativeGlobalAttention):\n  • v=tf.Tensor(shape=(1, 263, 1024), dtype=float32)\n  • k=tf.Tensor(shape=(1, 263, 1024), dtype=float32)\n  • q=tf.Tensor(shape=(1, 1, 192), dtype=float32)\n  • mask=tf.Tensor(shape=(1, 1, 1, 263), dtype=float32)"
     ]
    }
   ],
   "source": [
    "for trk in inp_path:\n",
    "    #get name\n",
    "    trk_name = trk.split('\\\\')[-1][:-4] #you may change it depending your OS\n",
    "    print('Generating..', trk_name)\n",
    "    \n",
    "    # PREPROCESSING (get the sequence of tokens)\n",
    "    rg_sequence = []\n",
    "    \n",
    "    with open(trk, 'r') as rg_file:\n",
    "        # Retrieve the sequence of tokens of the 16 first bars\n",
    "        rg_lines = rg_file.readlines()\n",
    "        count_measures = 0\n",
    "        rg_token_count = 0\n",
    "        for line in rg_lines:\n",
    "            rg_token_count+=1\n",
    "            if line.strip() == \"new_measure\":\n",
    "                count_measures+=1\n",
    "                if count_measures == thr_measures:\n",
    "                    break\n",
    "        \n",
    "            rg_sequence.append(line.strip())\n",
    "    \n",
    "    # POST PROCESSING\n",
    "    #create the Encoder: convert tokens to one-hot encoding\n",
    "    Enc_Input = create_onehot_enc(rg_sequence, TransEncoders)\n",
    "    #padding (add 0s to the input until it reaches length 793)\n",
    "    Enc_Input = Enc_Input + [0]*(dec_seq_length-len(Enc_Input))\n",
    "        \n",
    "    # call generation functions\n",
    "    bass_HB = generate_bass_ev_trans_tf(trans_bass_hb, TransEncoders, temperature, Enc_Input, dec_seq_length=dec_seq_length)      \n",
    "    # save token files to be passed to the tokens2gp5 algorithm\n",
    "    save_path = out_path+trk_name\n",
    "    save_path.replace('_rythmic', '_with_bass.txt')\n",
    "    bass_HB.write(save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Enc_Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_seq_length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP_DRUMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
