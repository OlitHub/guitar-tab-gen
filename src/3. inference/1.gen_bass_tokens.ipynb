{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to reload all modules (except those excluded by %aimport)\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for GPU inference\n",
    "from glob import glob\n",
    "import pickle as pickle\n",
    "from gen_utils import bass_trans_ev_model_tf, generate_bass_ev_trans_tf, create_onehot_enc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_measures = 16\n",
    "thr_max_tokens = 800\n",
    "thr_min_tokens = 50\n",
    "dec_seq_length = 797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load Encoders pickle for onehotencoders'''\n",
    "\n",
    "#encoders pickle is created during pre-processing\n",
    "encoders_trans = './aux_files/bass_encoders_cp.pickle'\n",
    "\n",
    "    \n",
    "with open(encoders_trans, 'rb') as handle:\n",
    "    TransEncoders = pickle.load(handle)\n",
    "#[Encoder_RG, Decoder_Bass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hybrid Music Transformer\n",
      "Latest checkpoint restored!\n"
     ]
    }
   ],
   "source": [
    "'''Load Inference Transformer. You may download pre-trained model based \n",
    "on the paper. See instructions in ReadME.md'''\n",
    "trans_bass_hb = bass_trans_ev_model_tf(TransEncoders, dec_seq_length)\n",
    "\n",
    "\n",
    "'''Set Temperature'''\n",
    "temperature = 0.9\n",
    "\n",
    "'''Load MIDI files with Guitar (1st) and Bass (2nd). See examples in midi_in folder'''\n",
    "'''max 16 bars'''\n",
    "#input folder (put txt token files of rg only here)\n",
    "inp_path = glob('./tokens_in/*.txt')\n",
    "#output folder\n",
    "out_path = './tokens_out/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on selected text token files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating.. ACDC - Highway to Hell_rythmic\n",
      "Already generated.. ACDC - Highway to Hell_rythmic\n",
      "Generating.. Genesis - I Can't Dance_rythmic\n",
      "Already generated.. Genesis - I Can't Dance_rythmic\n",
      "Generating.. Kings Of Leon-California Waiting\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32464\\1521501834.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# POST PROCESSING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m#create the Encoder: convert tokens to one-hot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mEnc_Input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_onehot_enc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrg_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransEncoders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m#padding (add 0s to the input until it reaches length 793)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mEnc_Input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnc_Input\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_seq_length\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEnc_Input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\gen_utils.py\u001b[0m in \u001b[0;36mcreate_onehot_enc\u001b[1;34m(Encoder_RG, TransEncoders)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mEnc_Input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransEncoders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mEncoder_RG\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mEnc_Input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mEnc_Input\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#for embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mEnc_Input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mEnc_Input\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#shift by one in order to have 0 as pad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\gen_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mEnc_Input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransEncoders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mEncoder_RG\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mEnc_Input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mEnc_Input\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#for embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mEnc_Input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mEnc_Input\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#shift by one in order to have 0 as pad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "for trk in inp_path:\n",
    "    #get name\n",
    "    trk_name = trk.split('\\\\')[-1][:-4] #you may change it depending your OS\n",
    "    print('Generating..', trk_name)\n",
    "    save_path = out_path+trk_name\n",
    "    save_path = save_path.replace('_rythmic', '_with_bass_' + str(temperature) + '.txt')\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        print('Already generated..', trk_name)\n",
    "        continue\n",
    "    # PREPROCESSING (get the sequence of tokens)\n",
    "    rg_sequence = []\n",
    "    \n",
    "    with open(trk, 'r') as rg_file:\n",
    "        # Retrieve the sequence of tokens of the 16 first bars\n",
    "        rg_lines = rg_file.readlines()\n",
    "        count_measures = 0\n",
    "        rg_token_count = 0\n",
    "        for line in rg_lines:\n",
    "            rg_token_count+=1\n",
    "            if line.strip() == \"new_measure\":\n",
    "                count_measures+=1\n",
    "                if count_measures == thr_measures:\n",
    "                    break\n",
    "        \n",
    "            rg_sequence.append(line.strip())\n",
    "    \n",
    "    # POST PROCESSING\n",
    "    #create the Encoder: convert tokens to one-hot encoding\n",
    "    Enc_Input = create_onehot_enc(rg_sequence, TransEncoders)\n",
    "    #padding (add 0s to the input until it reaches length 793)\n",
    "    Enc_Input = Enc_Input + [0]*(dec_seq_length-len(Enc_Input))\n",
    "\n",
    "    # call generation functions\n",
    "    bass_HB = generate_bass_ev_trans_tf(trans_bass_hb, TransEncoders, temperature, Enc_Input, dec_seq_length=dec_seq_length)      \n",
    "    # save token files to be passed to the tokens2gp5 algorithm\n",
    "    with open(save_path, 'w') as f:\n",
    "        for token in bass_HB:\n",
    "            f.write(\"%s\\n\" % token)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/797 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"embedding\" \"                 f\"(type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,69] = 1887 is not in [0, 1755) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding\" \"                 f\"(type Embedding):\n  • inputs=tf.Tensor(shape=(1, 797), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4044\\3366140845.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mEnc_Input\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menc_input_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# call generation functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mbass_HB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_bass_ev_trans_tf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans_bass_hb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransEncoders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEnc_Input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_seq_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdec_seq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;31m# save token files to be passed to the tokens2gp5 algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0moutput_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbass_HB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\gen_utils.py\u001b[0m in \u001b[0;36mgenerate_bass_ev_trans_tf\u001b[1;34m(trans_bass, TransEncoders, temperature, Encoder_RG, dec_seq_length)\u001b[0m\n\u001b[0;32m     64\u001b[0m        \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEncoder_RG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_out_bass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m        \u001b[0mpreds_bass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrans_bass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEncoder_RG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_out_bass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m        \u001b[1;31m#bass Out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\CP_DRUMS\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\aux_files\\aux_train_tf.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inp, tar, look_ahead_mask, dec_padding_mask, training)\u001b[0m\n\u001b[0;32m    441\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlook_ahead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m     \u001b[0menc_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (batch_size, inp_seq_len, dff)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;31m# dec_output.shape == (batch_size, tar_seq_len, d_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Github\\guitar-tab-gen\\src\\3. inference\\aux_files\\aux_train_tf.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;31m# adding embedding and position encoding.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (batch_size, input_seq_len, d_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;31m# x = tf.keras.layers.Concatenate()([x])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"embedding\" \"                 f\"(type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,69] = 1887 is not in [0, 1755) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding\" \"                 f\"(type Embedding):\n  • inputs=tf.Tensor(shape=(1, 797), dtype=int32)"
     ]
    }
   ],
   "source": [
    "test_path = r\"..\\..\\data\\processed\\test_set_streams_16_8_800_50.pickle\"\n",
    "\n",
    "with open(test_path, 'rb') as handle:\n",
    "    testSet = pickle.load(handle)\n",
    "\n",
    "enc_input_test = np.int64(np.stack(testSet['Encoder_Input'])) #encoder input\n",
    "output_test = []\n",
    "\n",
    "for Enc_Input in enc_input_test:\n",
    "    # call generation functions\n",
    "    bass_HB = generate_bass_ev_trans_tf(trans_bass_hb, TransEncoders, temperature, Enc_Input, dec_seq_length=dec_seq_length)      \n",
    "    # save token files to be passed to the tokens2gp5 algorithm\n",
    "    output_test.append(bass_HB)\n",
    "    \n",
    "# output_test is a list of lists of tokens for the 11 817 test set sequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP_DRUMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
