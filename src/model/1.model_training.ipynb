{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "Load the pickle file, split in train and test set, and train the model from CP_Drums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to reload all modules (except those excluded by %aimport)\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import pickle5 as pickle\n",
    "import ast\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import tensorflow as tf\n",
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from aux_train_tf import HybridTransformer, create_masks\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_encoder = 975\n",
    "n_decoder = 738\n",
    "\n",
    "train_path = \"..\\..\\data\\\\train_set_streams.pickle\"\n",
    "test_path = \"..\\..\\data\\\\test_set_streams.pickle\"\n",
    "\n",
    "with open(train_path, 'rb') as handle:\n",
    "    trainSet = pickle.load(handle)\n",
    "\n",
    "with open(test_path, 'rb') as handle:\n",
    "    testSet = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 345\n",
      "steps_per_epoch_eval: 60\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "enc_input_train = np.int64(np.stack(trainSet['Encoder_Input'])) #encoder input\n",
    "dec_input_train = np.int64(np.stack(trainSet['Decoder_Input'])) #decoder onset stream\n",
    "dec_output_train = np.int64(np.stack(trainSet['Decoder_Output']))\n",
    "#validation\n",
    "enc_input_val = np.int64(np.stack(testSet['Encoder_Input']))\n",
    "dec_input_val = np.int64(np.stack(testSet['Decoder_Input']))\n",
    "dec_output_val = np.int64(np.stack(testSet['Decoder_Output']))\n",
    "\n",
    "\n",
    "#prepare datasets\n",
    "BUFFER_SIZE = len(enc_input_train)\n",
    "BUFFER_SIZE_EVAL = len(enc_input_val)\n",
    "BATCH_SIZE = 32 #set batch size\n",
    "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
    "steps_per_epoch_eval = BUFFER_SIZE_EVAL//BATCH_SIZE\n",
    "\n",
    "print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "print(f\"steps_per_epoch_eval: {steps_per_epoch_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training and evaluation tf dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_input_train, \n",
    "                                              dec_input_train, dec_output_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_eval = tf.data.Dataset.from_tensor_slices((enc_input_val,\n",
    "                                                   dec_input_val, dec_output_val)).shuffle(BUFFER_SIZE_EVAL)\n",
    "dataset_eval = dataset_eval.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "\n",
    "#set transformer hyper parameters\n",
    "num_layers = 4  #attention layers\n",
    "#Embeddings\n",
    "d_model_enc = 240 #Encoder Embedding (64 + 16 + 32 + 64 + 64)\n",
    "\n",
    "d_model_dec = 192 #Decoder Embedding (96 + 96)\n",
    "\n",
    "units = 1024 #for Dense Layers and BLSTM Encoder\n",
    "num_heads = 8 #\n",
    "dropout_rate = 0.3\n",
    "\n",
    "#vocab sizes\n",
    "enc_vocab = 1724\n",
    "dec_vocab = 1078\n",
    "\n",
    "#sequence lengths\n",
    "enc_seq_length = 975\n",
    "dec_seq_length = 738\n",
    "\n",
    "#for relative attention half or full window\n",
    "rel_dec_seq = dec_seq_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridTransformer(num_layers=num_layers, d_model_enc=d_model_enc,\n",
    "                          d_model_dec=d_model_dec, num_heads=num_heads,\n",
    "                          dff=units, input_vocab=enc_vocab+1, target_vocab=dec_vocab+1, \n",
    "                          pe_target=dec_seq_length, \n",
    "                          mode_choice='relative', #change to multihead for vanilla attention mechanism\n",
    "                          max_rel_pos_tar=rel_dec_seq, rate=dropout_rate)\n",
    "\n",
    "\n",
    "#Set Optimizers and Loss Function\n",
    "optimizer = tf.keras.optimizers.Adam(0.0005, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "#Set TF Metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.Mean(name='val_accuracy')\n",
    "\n",
    "#Set Checkpoints\n",
    "checkpoint_path = './checkpoints/'\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print('Latest checkpoint restored!!')\n",
    "\n",
    "# Set input signatures\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64)\n",
    "]\n",
    "\n",
    "val_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64)\n",
    "]\n",
    "\n",
    "\n",
    "'''Training and Validation functions'''\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar_inp, tar_real):\n",
    "\n",
    "  _, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    preds, _ = model(\tinp,\n",
    "\t\t\t\t\t\ttar_inp,\n",
    "\t\t\t\t\t\tTrue,\n",
    "\t\t\t\t\t\tcombined_mask,\n",
    "\t\t\t\t\t\tdec_padding_mask)\n",
    "    \n",
    "    loss = loss_function(tar_real, preds)\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  \n",
    "  acc = accuracy_function(tar_real, preds)\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(acc)\n",
    "  \n",
    "  \n",
    "  \n",
    "@tf.function(input_signature=val_step_signature)\n",
    "def val_step(inp, tar_inp, tar_real):\n",
    "\n",
    "\n",
    "  _, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "  preds, _ = model(\tinp,\n",
    "\t\t\t\t\ttar_inp,\n",
    "\t\t\t\t\tFalse, #change?\n",
    "\t\t\t\t\tcombined_mask,\n",
    "\t\t\t\t\tdec_padding_mask)\n",
    "  \n",
    "  loss = loss_function(tar_real, preds)\n",
    "  \n",
    "  acc = accuracy_function(tar_real, preds)\n",
    "\n",
    "  val_loss(loss)\n",
    "  val_accuracy(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/345 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"START TRAINING\"\"\"\n",
    "epochs = 2\n",
    "patience = 0\n",
    "curr_loss = 99.99    \n",
    "for epoch in range(epochs):\n",
    "  start = time.time()\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  print(f'Epoch {epoch + 1}')\n",
    "  print('----')\n",
    "  for (batch, (inp, tar_inp, tar_real)) in tqdm(enumerate(dataset.take(steps_per_epoch)), total=steps_per_epoch):\n",
    "    train_step(inp, tar_inp, tar_real)\n",
    "\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print(f'Batch {batch}')\n",
    "      print(f'Onset Loss {train_loss.result():.4f} -- Onset Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "  print('----')\n",
    "  print(f'Onset Loss {train_loss.result():.4f} -- Onset Accuracy {train_accuracy.result():.4f}')\n",
    "  \n",
    "  \n",
    "  print('Evaluating...')\n",
    "\n",
    "  val_loss.reset_states()\n",
    "  val_accuracy.reset_states()  \n",
    "  \n",
    "  for (batch, (inp, tar_inp, tar_real)) in enumerate(dataset_eval.take(steps_per_epoch_eval)):\n",
    "    val_step(inp, tar_inp, tar_real)\n",
    "  \n",
    "  print('----')\n",
    "  print(f'Validation Onset Loss {val_loss.result():.4f} -- Onset Accuracy {val_accuracy.result():.4f}')  \n",
    "  \n",
    "  val_loss = np.round(val_loss.result().numpy(), decimals = 5) #change weights\n",
    "  print('Overall weighted Validation Loss: ', val_loss)\n",
    "  \n",
    "  '''EARLY STOP MECHANISM'''\n",
    "  if curr_loss > val_loss:\n",
    "    #save checkpoint\n",
    "    print('Checkpoint saved.')\n",
    "    patience = 0\n",
    "    save_path = ckpt_manager.save()\n",
    "    curr_loss = val_loss\n",
    "    \n",
    "  else:\n",
    "      print('No validation loss improvement.')\n",
    "      patience += 1\n",
    "      \n",
    "  print(f'Time taken for this epoch: {time.time() - start:.2f} secs\\n')    \n",
    "  print('*******************************')\n",
    "      \n",
    "  if patience > 5:\n",
    "      print('Terminating the training.')\n",
    "      break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP_DRUMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
