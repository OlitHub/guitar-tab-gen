{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "Load the pickle file, split in train and test set, and train the model from CP_Drums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to reload all modules (except those excluded by %aimport)\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import pickle5 as pickle\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_encoder = 545\n",
    "n_decoder = 597\n",
    "\n",
    "encoder_input = np.load(\"..\\..\\data\\encoder_input.npy\")\n",
    "decoder_input = np.load(\"..\\..\\data\\decoder_input.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into val and train data (shuffling but keeping same index for encoder and decoder)\n",
    "from sklearn.model_selection import train_test_split\n",
    "enc_input_train, enc_input_val, dec_input_train, dec_input_val = train_test_split(encoder_input, decoder_input, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to reload all modules (except those excluded by %aimport)\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import tensorflow as tf\n",
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from aux_train_tf import HybridTransformer, create_masks\n",
    "\n",
    "# physical_devices = tf.config.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare datasets\n",
    "BUFFER_SIZE = len(enc_input_train)\n",
    "BUFFER_SIZE_EVAL = len(enc_input_val)\n",
    "BATCH_SIZE = 32 #set batch size\n",
    "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
    "steps_per_epoch_eval = BUFFER_SIZE_EVAL//BATCH_SIZE\n",
    "\n",
    "#create training and evaluation tf dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_input_train, dec_input_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset_eval = tf.data.Dataset.from_tensor_slices((enc_input_val, dec_input_val)).shuffle(BUFFER_SIZE_EVAL)\n",
    "dataset_eval = dataset_eval.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "\n",
    "#set transformer hyper parameters\n",
    "num_layers = 4  #attention layers\n",
    "#Embeddings\n",
    "d_model_enc = 240 #Encoder Embedding (64 + 16 + 32 + 64 + 64)\n",
    "\n",
    "d_model_dec = 192 #Decoder Embedding (96 + 96)\n",
    "\n",
    "units = 1024 #for Dense Layers and BLSTM Encoder\n",
    "num_heads = 8 #\n",
    "dropout_rate = 0.3\n",
    "\n",
    "#vocab sizes\n",
    "enc_vocab = 3188\n",
    "dec_vocab = 3188\n",
    "\n",
    "#sequence lengths\n",
    "enc_seq_length = 597\n",
    "dec_seq_length = 545\n",
    "\n",
    "#for relative attention half or full window\n",
    "rel_dec_seq = dec_seq_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridTransformer(num_layers=num_layers, d_model_enc=d_model_enc,\n",
    "                          d_model_dec=d_model_dec, num_heads=num_heads,\n",
    "                          dff=units, input_vocab=enc_vocab+1, target_vocab=dec_vocab+1, \n",
    "                          pe_target=dec_seq_length, \n",
    "                          mode_choice='relative', #change to multihead for vanilla attention mechanism\n",
    "                          max_rel_pos_tar=rel_dec_seq, rate=dropout_rate)\n",
    "\n",
    "\n",
    "#Set Optimizers and Loss Function\n",
    "optimizer = tf.keras.optimizers.Adam(0.0005, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "\n",
    "#Set TF Metrics\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.Mean(name='val_accuracy')\n",
    "\n",
    "#Set Checkpoints\n",
    "checkpoint_path = './checkpoints/'\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print('Latest checkpoint restored!!')\n",
    "\n",
    "# Set input signatures\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64)\n",
    "]\n",
    "\n",
    "val_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64)\n",
    "]\n",
    "\n",
    "\n",
    "'''Training and Validation functions'''\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar_inp, tar_real):\n",
    "\n",
    "  _, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    preds, _ = model(\tinp,\n",
    "\t\t\t\t\t\ttar_inp,\n",
    "\t\t\t\t\t\tTrue,\n",
    "\t\t\t\t\t\tcombined_mask,\n",
    "\t\t\t\t\t\tdec_padding_mask)\n",
    "    \n",
    "    loss = loss_function(tar_real, preds)\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  \n",
    "  acc = accuracy_function(tar_real, preds)\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(acc)\n",
    "  \n",
    "  \n",
    "  \n",
    "@tf.function(input_signature=val_step_signature)\n",
    "def val_step(inp, tar_inp, tar_real):\n",
    "\n",
    "\n",
    "  _, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "  preds, _ = model(\tinp,\n",
    "\t\t\t\t\ttar_inp,\n",
    "\t\t\t\t\tFalse, #change?\n",
    "\t\t\t\t\tcombined_mask,\n",
    "\t\t\t\t\tdec_padding_mask)\n",
    "  \n",
    "  loss = loss_function(tar_real, preds)\n",
    "  \n",
    "  acc = accuracy_function(tar_real, preds)\n",
    "\n",
    "  val_loss(loss)\n",
    "  val_accuracy(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (32, 545) (32, 597)\n",
      "1 (32, 545) (32, 597)\n",
      "2 (32, 545) (32, 597)\n",
      "3 (32, 545) (32, 597)\n",
      "4 (32, 545) (32, 597)\n",
      "5 (32, 545) (32, 597)\n"
     ]
    }
   ],
   "source": [
    "for batch in enumerate(dataset.take(steps_per_epoch)):\n",
    "    print(batch[0], batch[1][0].shape, batch[1][1].shape)\n",
    "    if batch[0] == 5:\n",
    "        break\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "----\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13464\\2396867436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {epoch + 1}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'----'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar_inp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar_real\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar_inp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar_real\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "\"\"\"START TRAINING\"\"\"\n",
    "epochs = 2\n",
    "patience = 0\n",
    "curr_loss = 99.99    \n",
    "for epoch in range(epochs):\n",
    "  start = time.time()\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  print(f'Epoch {epoch + 1}')\n",
    "  print('----')\n",
    "  for (batch, (inp, tar_inp, tar_real)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    train_step(inp, tar_inp, tar_real)\n",
    "\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print(f'Batch {batch}')\n",
    "      print(f'Onset Loss {train_loss.result():.4f} -- Onset Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "  print('----')\n",
    "  print(f'Onset Loss {train_loss.result():.4f} -- Onset Accuracy {train_accuracy.result():.4f}')\n",
    "  \n",
    "  \n",
    "  print('Evaluating...')\n",
    "\n",
    "  val_loss.reset_states()\n",
    "  val_accuracy.reset_states()  \n",
    "  \n",
    "  for (batch, (inp, tar_inp, tar_real)) in enumerate(dataset_eval.take(steps_per_epoch_eval)):\n",
    "    val_step(inp, tar_inp, tar_real)\n",
    "  \n",
    "  print('----')\n",
    "  print(f'Validation Onset Loss {val_loss.result():.4f} -- Onset Accuracy {val_accuracy.result():.4f}')  \n",
    "  \n",
    "  val_loss = np.round(val_loss.result().numpy(), decimals = 5) #change weights\n",
    "  print('Overall weighted Validation Loss: ', val_loss)\n",
    "  \n",
    "  '''EARLY STOP MECHANISM'''\n",
    "  if curr_loss > val_loss:\n",
    "    #save checkpoint\n",
    "    print('Checkpoint saved.')\n",
    "    patience = 0\n",
    "    save_path = ckpt_manager.save()\n",
    "    curr_loss = val_loss\n",
    "    \n",
    "  else:\n",
    "      print('No validation loss improvement.')\n",
    "      patience += 1\n",
    "      \n",
    "  print(f'Time taken for this epoch: {time.time() - start:.2f} secs\\n')    \n",
    "  print('*******************************')\n",
    "      \n",
    "  if patience > 5:\n",
    "      print('Terminating the training.')\n",
    "      break\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP_DRUMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
