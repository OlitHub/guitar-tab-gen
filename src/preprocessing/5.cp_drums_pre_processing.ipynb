{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset in a big dict\n",
    "\n",
    "In this notebook we perform the conversion of the txt tokens to a 2D file containing for each song the sequence of ids of its tokens.\n",
    "For a song to be added to the dataset, it needs to contain bass guitar and a rhythmic guitar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import guitarpro as pygp\n",
    "import pathlib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_bass_folder = pathlib.Path(\"..\\..\\data\\BGTG\\BGTG_Bass\")\n",
    "thr_measures = 8\n",
    "thr_tokens = 1000\n",
    "# Iterate over all the alphabetical and group folders within each folders \n",
    "# For the first implementation we will assume that if a song has bass it also has RG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences of ids:   8%|▊         | 1095/14480 [00:02<00:29, 446.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song removed, too much tokens Audioslave - Cochise (2) 1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences of ids:  26%|██▋       | 3827/14480 [00:07<00:21, 502.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song removed, too much tokens Dimmu Borgir - Tormentor Of Christian Souls (2) 1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences of ids:  57%|█████▋    | 8196/14480 [02:35<03:48, 27.49it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song removed, too much tokens Mest - Rooftop 1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences of ids:  58%|█████▊    | 8452/14480 [02:46<03:54, 25.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song removed, too much tokens Millencolin - A - Ten 1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences of ids:  64%|██████▎   | 9211/14480 [03:18<03:47, 23.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song removed, too much tokens Nirvana - Molly's Lips (2) 1580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences of ids:  67%|██████▋   | 9680/14480 [03:38<03:25, 23.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song removed, too much tokens Opium - Rest in Peace 1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences of ids:  81%|████████  | 11726/14480 [05:02<01:43, 26.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song removed, too much tokens Scissor Sisters - Take Your Mama Out 1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences of ids:  94%|█████████▍| 13621/14480 [06:19<00:38, 22.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song removed, too much tokens Uncommonmenfrommars - Pizzaman 1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating sequences of ids: 100%|██████████| 14480/14480 [06:49<00:00, 35.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path errors:  1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop on the files of the bass folder, for each file check if there is a corresponding file in the RG folder\n",
    "# Then generate the bass sequence and the RG sequence \n",
    "path_errors=0\n",
    "path_errors_list=[]\n",
    "big_dict = {'All_Events':[], 'Encoder_RG':[], 'Decoder_Bass':[]}\n",
    "\n",
    "# big_dict will have the following structure:\n",
    "# keys: encoder_rg, decoder_bass\n",
    "# big_dict['encoder_rg'][0] = list of rg txt tokens for the first song\n",
    "# big_dict['decoder_bass'][0] = list of bass txt tokens for the first song\n",
    "\n",
    "for bass_file_path in tqdm(path_to_bass_folder.rglob(\"*.txt\"), total=14480, desc=\"Generating sequences of ids\"):\n",
    "    # Replace _bass with _rythmic and BGTG_Bass by BGTG_RG to get the corresponding RG file\n",
    "    rg_file_path = pathlib.Path((str(bass_file_path).replace(\"_bass.txt\", \"_rythmic.txt\")).replace(\"BGTG_Bass\", \"BGTG_RG\"))\n",
    "    all_file_path = pathlib.Path((str(bass_file_path).replace(\"_bass.txt\", \"_rythmic.txt\")).replace(\"BGTG_Bass\", \"BGTG_RG_Bass\"))\n",
    "\n",
    "    song_name = bass_file_path.stem.split(\"_\")[0]\n",
    "    \n",
    "    if rg_file_path.exists() and all_file_path.exists():\n",
    "        bass_sequence = []\n",
    "        rg_sequence = []\n",
    "        all_events_sequence = []\n",
    "        remove_song = False\n",
    "        # Truncate the token sequences at a certain number of measures\n",
    "        # Remove the token sequences that have too much tokens\n",
    "        \n",
    "        # Open the bass file\n",
    "        with open(bass_file_path, 'r') as bass_file:\n",
    "            bass_lines = bass_file.readlines()\n",
    "            count_measures = 0\n",
    "            token_count = 0\n",
    "            for line in bass_lines:\n",
    "                token_count+=1\n",
    "                if line.strip() == \"new_measure\":\n",
    "                    count_measures+=1\n",
    "                    if count_measures == thr_measures:\n",
    "                        break\n",
    "                \n",
    "                if token_count > thr_tokens:\n",
    "                    remove_song = True\n",
    "\n",
    "                bass_sequence.append(line.strip())\n",
    "\t\t\t\t\n",
    "        with open(rg_file_path, 'r') as rg_file:\n",
    "            rg_lines = rg_file.readlines()\n",
    "            count_measures = 0\n",
    "            token_count = 0\n",
    "            for line in rg_lines:\n",
    "                token_count+=1\n",
    "                if line.strip() == \"new_measure\":\n",
    "                    count_measures+=1\n",
    "                    if count_measures == thr_measures:\n",
    "                        break\n",
    "                    \n",
    "                if token_count > thr_tokens:\n",
    "                    remove_song = True\n",
    "            \n",
    "                rg_sequence.append(line.strip())\n",
    "                \n",
    "        with open(all_file_path, 'r') as all_file:\n",
    "            all_lines = all_file.readlines()\n",
    "            count_measures = 0\n",
    "            for line in all_lines:\n",
    "                if line.strip() == \"new_measure\":\n",
    "                    count_measures+=1\n",
    "                    if count_measures == thr_measures:\n",
    "                        break\n",
    "\n",
    "                all_events_sequence.append(line.strip())\n",
    "        \n",
    "        if remove_song:\n",
    "            print(\"Song removed, too much tokens\", song_name, token_count)\n",
    "        else:\n",
    "            big_dict['Encoder_RG'].append(rg_sequence)\n",
    "            big_dict['Decoder_Bass'].append(bass_sequence)\n",
    "            big_dict['All_Events'].append(all_events_sequence)\n",
    "        \n",
    "    else:\n",
    "        path_errors+=1\n",
    "        path_errors_list.append((song_name, bass_file_path, rg_file_path, all_file_path))\n",
    "\n",
    "print(\"Path errors: \", path_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the big_dict to a pickle file\n",
    "\n",
    "with open(\"..\\..\\data\\preprocessed_dadagp_\" + str(thr_measures) + '_' + str(thr_tokens) + \".pickle\", \"wb\") as handle:\n",
    "    pickle.dump(big_dict, handle, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13000, 13000, 13000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_dict['Encoder_RG']), len(big_dict['Decoder_Bass']), len(big_dict['All_Events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max encoder length:  973\n",
      "Max decoder length:  737\n"
     ]
    }
   ],
   "source": [
    "max_enc_length = 0\n",
    "max_dec_length = 0\n",
    "index_enc = 0\n",
    "index_dec = 0\n",
    "\n",
    "for k in range(0, len(big_dict['Encoder_RG'])):\n",
    "    \n",
    "    #get max seq_lengths\n",
    "    if max_enc_length < len(big_dict['Encoder_RG'][k]):\n",
    "        max_enc_length = len(big_dict['Encoder_RG'][k])\n",
    "        index_enc = k\n",
    "    if max_dec_length < len(big_dict['Decoder_Bass'][k]):\n",
    "        max_dec_length = len(big_dict['Decoder_Bass'][k])\n",
    "        index_dec = k\n",
    "        \n",
    "print(\"Max encoder length: \", max_enc_length)\n",
    "print(\"Max decoder length: \", max_dec_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DADAGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
