08/10/2024
Learn about transformers. Try a DadaGP model to generate something and turn it to a score.

----------------------------------------------------------------------------------------------------------------------------

16/10/2024
Tested DadaGP model on free generation.
I should try to better understand Pedro's code and generate only a bass guitar score if it is possible.
I can try to modify the prompt to generate only bass guitar scores.
Or I can put the probabilities of the tokens that are not bass guitar notes to zero.
This will give us a baseline.

Also try to generate specific style of music using the artist in the prompt.

How does DadaGP sample?
Also, read GTR-CTRL paper and try to understand the model.

I may have to retrain the model on bass guitar scores only or to at least fine-tune the model on bass guitar scores.
This will give us a better baseline.
I should create a kaggle or colab notebook for the training and inference as I will need computational resources.
Colab can connect to a github repository and I can use the free GPU provided by google.

----------------------------------------------------------------------------------------------------------------------------

22/10/2024

Tried understanding the code from the DadaGP checkpoint. DadaGP seems to be a TransformerXL extended with MemTransformerLM.
Ask Pedro about this.

I tried generating an only bass guitar score using the prompt but it doesn't seem possible just like that.
My prompt was to start the generation with a note of bass guitar only. It delays the appearance of other instruments but they still appear after a while.
I also tried generating in the style of the Beatles as there is a consistent dataset of their songs.

GTR-CTRL:
CTRL model does conditional generation using categorization tokens appended to text sequences.

Look at pkl files of the vocabulary in a notebook, retrieve the unwanted instruments tokens and set their probabilities to 0 in the logits.
--> baseline

Look at github CP Drums Generation and their model to understand how the conditional information is given to the decoder.

08/11/2024

I generated some baselines by setting the logits of the other instruments to 0 but it wasn't great.
--> We need to try something else.

Look at dadagp.py and modify it to output a new token text version of the gp files.
Look at the mapping between int and instruments in pyguitarpro
We should have token text files for each instruments of the track
so that we can choose which instruments we use to condition the bass:

Especially, we need one with the rythmic guitar, and one with the drums.

Then we of course need one with the bass guitar (input and testing output).

Once we successfully have this training data, we will try the model from the CP Drums Generation article on it.
(BiLSTM + Word Decoder)

13/11/2024

Generating the txt tokens file using a notebook.

Add a function to cumulate the consecutive waits.
Add the instruments to keep as a parameter of the function!
Try to apply the notebook to a large number of files.
Output the generated files in a separate folder.

Next step is to identify the rythmic guitar to be able to condition on it.
We also could try to identify the genre of the artists and add a token for it.
This would allow us to condition the generation on the genre.



